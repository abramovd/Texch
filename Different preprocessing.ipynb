{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from random import Random\n",
    "from texch.experiments import ClusteringExperiment, MultiClusteringExperiment\n",
    "from texch.clustering.nltk import KMeansClusterer\n",
    "from texch.preprocessing import PreprocessStep, Preprocessor\n",
    "from texch.preprocessing.sklearn import TfidfVectorizer\n",
    "from texch.clustering.nltk import KMeansClusterer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "dataset = fetch_20newsgroups(\n",
    "    categories=[\n",
    "        'alt.atheism', 'talk.religion.misc',\n",
    "        'comp.graphics', 'sci.space'\n",
    "    ],\n",
    "    subset='test',\n",
    "    random_state=42\n",
    ")\n",
    "labels = dataset.target\n",
    "true_k = np.unique(labels).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "stopwords_uni =  Preprocessor(\n",
    "    [TfidfVectorizer().as_preprocess_step()]\n",
    ")\n",
    "stopwords_bi =  Preprocessor(\n",
    "    [TfidfVectorizer(ngram_range=(2, 2)).as_preprocess_step()]\n",
    ")\n",
    "stopwords_tri = Preprocessor(\n",
    "    [TfidfVectorizer(ngram_range=(3, 3)).as_preprocess_step()]\n",
    ")\n",
    "stopwords_uni_bi = Preprocessor(\n",
    "    [TfidfVectorizer(stop_words='english', ngram_range=(1, 2)).as_preprocess_step()]\n",
    ")\n",
    "stopwords_bi_tri = Preprocessor(\n",
    "    [TfidfVectorizer(stop_words='english', ngram_range=(2, 3)).as_preprocess_step()]\n",
    ")\n",
    "stopwords_uni_bi_tri = Preprocessor(\n",
    "    [TfidfVectorizer(stop_words='english', ngram_range=(1, 3)).as_preprocess_step()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "experiments = [\n",
    "    ClusteringExperiment(\n",
    "        method=KMeansClusterer(\n",
    "            true_k,\n",
    "            distance=euclidean,\n",
    "            rng=Random(10)\n",
    "        ),\n",
    "        preprocessor=Preprocessor(\n",
    "            [TfidfVectorizer(stop_words='english').as_preprocess_step()]\n",
    "        ),\n",
    "        prepare_func=lambda d: d.todense(),\n",
    "        verbose_name='stopwords removed unigrams'\n",
    "    ),\n",
    "    ClusteringExperiment(\n",
    "        method=KMeansClusterer(\n",
    "            true_k,\n",
    "            distance=euclidean,\n",
    "            rng=Random(10)\n",
    "        ),\n",
    "        preprocessor=Preprocessor(\n",
    "            [TfidfVectorizer().as_preprocess_step()]\n",
    "        ),\n",
    "        prepare_func=lambda d: d.todense(),\n",
    "        verbose_name='with stopwords unigrams'\n",
    "    ),\n",
    "     ClusteringExperiment(\n",
    "        method=KMeansClusterer(\n",
    "            true_k,\n",
    "            distance=euclidean,\n",
    "            rng=Random(10)\n",
    "        ),\n",
    "        preprocessor=Preprocessor(\n",
    "            [TfidfVectorizer(stop_words='english', ngram_range=(1,2)).as_preprocess_step()]\n",
    "        ),\n",
    "        prepare_func=lambda d: d.todense(),\n",
    "        verbose_name='stopwords removed unigrams + bigrams'\n",
    "    ),\n",
    "    ClusteringExperiment(\n",
    "        method=KMeansClusterer(\n",
    "            true_k,\n",
    "            distance=euclidean,\n",
    "            rng=Random(10)\n",
    "        ),\n",
    "        preprocessor=Preprocessor(\n",
    "            [TfidfVectorizer(ngram_range=(1,2)).as_preprocess_step()]\n",
    "        ),\n",
    "        prepare_func=lambda d: d.todense(),\n",
    "        verbose_name='with stopwords unigrams + bigrams'\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "stopwords_ngrams = MultiClusteringExperiment(\n",
    "    data=dataset.data,\n",
    "    experiments=experiments,\n",
    "    verbose_name='Stopwords removed with different N-grams'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running multi experiment consisting of 6 sub experiments\n",
      "\n",
      "--------------------------------------------------\n",
      "*****Experiment #0*****\n",
      "Running experiment \"unigrams (id=18)\"...\n",
      "Running preprocessing...\n",
      "Step #0: PreprocessStep (id=12): finished in 0.772240877151 sec\n",
      "Finished preprocessing in 0.772240877151\n",
      "Running in-middle prepare function...\n",
      "Finished in-middle prepare function in 0.246671915054 sec\n",
      "Running method...\n",
      "Finished method in 12.2098829746 sec\n",
      "Finished experiment in 13.2287957668 sec\n",
      "\n",
      "--------------------------------------------------\n",
      "*****Experiment #1*****\n",
      "Running experiment \"bigrams (id=19)\"...\n",
      "Running preprocessing...\n",
      "Step #0: PreprocessStep (id=13): finished in 3.34141516685 sec\n",
      "Finished preprocessing in 3.34141516685\n",
      "Running in-middle prepare function...\n",
      "Finished in-middle prepare function in 0.577143907547 sec\n",
      "Running method...\n",
      "Finished method in 38.8899209499 sec\n",
      "Finished experiment in 42.8084800243 sec\n",
      "\n",
      "--------------------------------------------------\n",
      "*****Experiment #2*****\n",
      "Running experiment \"trigrams (id=20)\"...\n",
      "Running preprocessing...\n",
      "Step #0: PreprocessStep (id=14): finished in 2.56936717033 sec\n",
      "Finished preprocessing in 2.56936717033\n",
      "Running in-middle prepare function...\n",
      "Finished in-middle prepare function in 0.538190126419 sec\n",
      "Running method...\n",
      "Finished method in 55.0948760509 sec\n",
      "Finished experiment in 58.2024333477 sec\n",
      "\n",
      "--------------------------------------------------\n",
      "*****Experiment #3*****\n",
      "Running experiment \"unigrams + bigrams (id=21)\"...\n",
      "Running preprocessing...\n",
      "Step #0: PreprocessStep (id=15): finished in 2.56800818443 sec\n",
      "Finished preprocessing in 2.56800818443\n",
      "Running in-middle prepare function...\n",
      "Finished in-middle prepare function in 0.983027935028 sec\n",
      "Running method...\n",
      "Finished method in 86.4912531376 sec\n",
      "Finished experiment in 90.042289257 sec\n",
      "\n",
      "--------------------------------------------------\n",
      "*****Experiment #4*****\n",
      "Running experiment \"bigrams + trigrams (id=22)\"...\n",
      "Running preprocessing...\n",
      "Step #0: PreprocessStep (id=16): finished in 3.06211280823 sec\n",
      "Finished preprocessing in 3.06211280823\n",
      "Running in-middle prepare function...\n",
      "Finished in-middle prepare function in 0.537451028824 sec\n",
      "Running method...\n",
      "Finished method in 192.459998131 sec\n",
      "Finished experiment in 196.059561968 sec\n",
      "\n",
      "--------------------------------------------------\n",
      "*****Experiment #5*****\n",
      "Running experiment \"unigrams + bigrams + trigrams (id=23)\"...\n",
      "Running preprocessing...\n",
      "Step #0: PreprocessStep (id=17): finished in 3.95241689682 sec\n",
      "Finished preprocessing in 3.95241689682\n",
      "Running in-middle prepare function...\n",
      "Finished in-middle prepare function in 0.581374168396 sec\n",
      "Running method...\n",
      "Finished method in 202.907461882 sec\n",
      "Finished experiment in 207.441252947 sec\n",
      "Finished multi experiment in 607.782813311 sec\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <center>\n",
       "        <h1> Multi Experiment Stopwords removed with different N-grams </h1><br>\n",
       "        <h2>Summary</h2>:\n",
       "        </center>\n",
       "        <b>Experiments</b>:<br>\n",
       "        <ul><li>unigrams (id=18)</li><li>bigrams (id=19)</li><li>trigrams (id=20)</li><li>unigrams + bigrams (id=21)</li><li>bigrams + trigrams (id=22)</li><li>unigrams + bigrams + trigrams (id=23)</li></ul>\n",
       "\n",
       "<br><br>Computed scores:<br><br><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ExperimentID</th>\n",
       "      <th>ExperimentName</th>\n",
       "      <th>PreprocessorSpent</th>\n",
       "      <th>MethodSpent</th>\n",
       "      <th>TotalSpent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>unigrams</td>\n",
       "      <td>0.772241</td>\n",
       "      <td>12.209883</td>\n",
       "      <td>13.228796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>bigrams</td>\n",
       "      <td>3.341415</td>\n",
       "      <td>38.889921</td>\n",
       "      <td>42.808480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>trigrams</td>\n",
       "      <td>2.569367</td>\n",
       "      <td>55.094876</td>\n",
       "      <td>58.202433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>unigrams + bigrams</td>\n",
       "      <td>2.568008</td>\n",
       "      <td>86.491253</td>\n",
       "      <td>90.042289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>bigrams + trigrams</td>\n",
       "      <td>3.062113</td>\n",
       "      <td>192.459998</td>\n",
       "      <td>196.059562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23</td>\n",
       "      <td>unigrams + bigrams + trigrams</td>\n",
       "      <td>3.952417</td>\n",
       "      <td>202.907462</td>\n",
       "      <td>207.441253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "\n",
       "            Multi Experiment Stopwords removed with different N-grams.\n",
       "\n",
       "            Experiments:\n",
       "\n",
       "\n",
       "        \n",
       "\n",
       "\n",
       "\n",
       "Scores:\n",
       "\n",
       "   ExperimentID                 ExperimentName  PreprocessorSpent  \\\n",
       "0            18                       unigrams           0.772241   \n",
       "1            19                        bigrams           3.341415   \n",
       "2            20                       trigrams           2.569367   \n",
       "3            21             unigrams + bigrams           2.568008   \n",
       "4            22             bigrams + trigrams           3.062113   \n",
       "5            23  unigrams + bigrams + trigrams           3.952417   \n",
       "\n",
       "   MethodSpent  TotalSpent  \n",
       "0    12.209883   13.228796  \n",
       "1    38.889921   42.808480  \n",
       "2    55.094876   58.202433  \n",
       "3    86.491253   90.042289  \n",
       "4   192.459998  196.059562  \n",
       "5   202.907462  207.441253  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords_ngrams.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ExperimentID</th>\n",
       "      <th>ExperimentName</th>\n",
       "      <th>PreprocessorSpent</th>\n",
       "      <th>MethodSpent</th>\n",
       "      <th>TotalSpent</th>\n",
       "      <th>entropy</th>\n",
       "      <th>homogeneity</th>\n",
       "      <th>v_measure</th>\n",
       "      <th>adj_rand_index</th>\n",
       "      <th>completeness</th>\n",
       "      <th>mutual_info_score</th>\n",
       "      <th>normalized_mutual_info_score</th>\n",
       "      <th>adjusted_mutual_info_score</th>\n",
       "      <th>fowlkes_mallows_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>unigrams</td>\n",
       "      <td>0.772241</td>\n",
       "      <td>12.209883</td>\n",
       "      <td>13.228796</td>\n",
       "      <td>1.312428</td>\n",
       "      <td>0.435405</td>\n",
       "      <td>0.444882</td>\n",
       "      <td>0.399010</td>\n",
       "      <td>0.454781</td>\n",
       "      <td>0.596867</td>\n",
       "      <td>0.444987</td>\n",
       "      <td>0.434026</td>\n",
       "      <td>0.561498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>bigrams</td>\n",
       "      <td>3.341415</td>\n",
       "      <td>38.889921</td>\n",
       "      <td>42.808480</td>\n",
       "      <td>1.129509</td>\n",
       "      <td>0.009562</td>\n",
       "      <td>0.010485</td>\n",
       "      <td>0.002215</td>\n",
       "      <td>0.011605</td>\n",
       "      <td>0.013108</td>\n",
       "      <td>0.010534</td>\n",
       "      <td>0.007128</td>\n",
       "      <td>0.303138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>trigrams</td>\n",
       "      <td>2.569367</td>\n",
       "      <td>55.094876</td>\n",
       "      <td>58.202433</td>\n",
       "      <td>0.901741</td>\n",
       "      <td>0.023336</td>\n",
       "      <td>0.028152</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>0.035475</td>\n",
       "      <td>0.031989</td>\n",
       "      <td>0.028772</td>\n",
       "      <td>0.020886</td>\n",
       "      <td>0.341644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>unigrams + bigrams</td>\n",
       "      <td>2.568008</td>\n",
       "      <td>86.491253</td>\n",
       "      <td>90.042289</td>\n",
       "      <td>1.282587</td>\n",
       "      <td>0.345635</td>\n",
       "      <td>0.357131</td>\n",
       "      <td>0.299086</td>\n",
       "      <td>0.369417</td>\n",
       "      <td>0.473809</td>\n",
       "      <td>0.357328</td>\n",
       "      <td>0.344037</td>\n",
       "      <td>0.495246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>bigrams + trigrams</td>\n",
       "      <td>3.062113</td>\n",
       "      <td>192.459998</td>\n",
       "      <td>196.059562</td>\n",
       "      <td>1.182285</td>\n",
       "      <td>0.007724</td>\n",
       "      <td>0.008295</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>0.008956</td>\n",
       "      <td>0.010589</td>\n",
       "      <td>0.008317</td>\n",
       "      <td>0.005288</td>\n",
       "      <td>0.290055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23</td>\n",
       "      <td>unigrams + bigrams + trigrams</td>\n",
       "      <td>3.952417</td>\n",
       "      <td>202.907462</td>\n",
       "      <td>207.441253</td>\n",
       "      <td>1.231872</td>\n",
       "      <td>0.277614</td>\n",
       "      <td>0.292436</td>\n",
       "      <td>0.224648</td>\n",
       "      <td>0.308931</td>\n",
       "      <td>0.380563</td>\n",
       "      <td>0.292854</td>\n",
       "      <td>0.275849</td>\n",
       "      <td>0.450947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ExperimentID                 ExperimentName  PreprocessorSpent  \\\n",
       "0            18                       unigrams           0.772241   \n",
       "1            19                        bigrams           3.341415   \n",
       "2            20                       trigrams           2.569367   \n",
       "3            21             unigrams + bigrams           2.568008   \n",
       "4            22             bigrams + trigrams           3.062113   \n",
       "5            23  unigrams + bigrams + trigrams           3.952417   \n",
       "\n",
       "   MethodSpent  TotalSpent   entropy  homogeneity  v_measure  adj_rand_index  \\\n",
       "0    12.209883   13.228796  1.312428     0.435405   0.444882        0.399010   \n",
       "1    38.889921   42.808480  1.129509     0.009562   0.010485        0.002215   \n",
       "2    55.094876   58.202433  0.901741     0.023336   0.028152        0.000420   \n",
       "3    86.491253   90.042289  1.282587     0.345635   0.357131        0.299086   \n",
       "4   192.459998  196.059562  1.182285     0.007724   0.008295        0.000358   \n",
       "5   202.907462  207.441253  1.231872     0.277614   0.292436        0.224648   \n",
       "\n",
       "   completeness  mutual_info_score  normalized_mutual_info_score  \\\n",
       "0      0.454781           0.596867                      0.444987   \n",
       "1      0.011605           0.013108                      0.010534   \n",
       "2      0.035475           0.031989                      0.028772   \n",
       "3      0.369417           0.473809                      0.357328   \n",
       "4      0.008956           0.010589                      0.008317   \n",
       "5      0.308931           0.380563                      0.292854   \n",
       "\n",
       "   adjusted_mutual_info_score  fowlkes_mallows_score  \n",
       "0                    0.434026               0.561498  \n",
       "1                    0.007128               0.303138  \n",
       "2                    0.020886               0.341644  \n",
       "3                    0.344037               0.495246  \n",
       "4                    0.005288               0.290055  \n",
       "5                    0.275849               0.450947  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords_ngrams.set_true_labels(labels)\n",
    "stopwords_ngrams.compute_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ExperimentID</th>\n",
       "      <th>ExperimentName</th>\n",
       "      <th>PreprocessorSpent</th>\n",
       "      <th>MethodSpent</th>\n",
       "      <th>TotalSpent</th>\n",
       "      <th>entropy</th>\n",
       "      <th>homogeneity</th>\n",
       "      <th>v_measure</th>\n",
       "      <th>adj_rand_index</th>\n",
       "      <th>completeness</th>\n",
       "      <th>mutual_info_score</th>\n",
       "      <th>normalized_mutual_info_score</th>\n",
       "      <th>adjusted_mutual_info_score</th>\n",
       "      <th>fowlkes_mallows_score</th>\n",
       "      <th>silhouette_coefficient</th>\n",
       "      <th>calinski_harabaz_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>unigrams</td>\n",
       "      <td>0.772241</td>\n",
       "      <td>12.209883</td>\n",
       "      <td>13.228796</td>\n",
       "      <td>1.312428</td>\n",
       "      <td>0.435405</td>\n",
       "      <td>0.444882</td>\n",
       "      <td>0.399010</td>\n",
       "      <td>0.454781</td>\n",
       "      <td>0.596867</td>\n",
       "      <td>0.444987</td>\n",
       "      <td>0.434026</td>\n",
       "      <td>0.561498</td>\n",
       "      <td>0.006384</td>\n",
       "      <td>7.005031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>bigrams</td>\n",
       "      <td>3.341415</td>\n",
       "      <td>38.889921</td>\n",
       "      <td>42.808480</td>\n",
       "      <td>1.129509</td>\n",
       "      <td>0.009562</td>\n",
       "      <td>0.010485</td>\n",
       "      <td>0.002215</td>\n",
       "      <td>0.011605</td>\n",
       "      <td>0.013108</td>\n",
       "      <td>0.010534</td>\n",
       "      <td>0.007128</td>\n",
       "      <td>0.303138</td>\n",
       "      <td>0.001341</td>\n",
       "      <td>2.086874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>trigrams</td>\n",
       "      <td>2.569367</td>\n",
       "      <td>55.094876</td>\n",
       "      <td>58.202433</td>\n",
       "      <td>0.901741</td>\n",
       "      <td>0.023336</td>\n",
       "      <td>0.028152</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>0.035475</td>\n",
       "      <td>0.031989</td>\n",
       "      <td>0.028772</td>\n",
       "      <td>0.020886</td>\n",
       "      <td>0.341644</td>\n",
       "      <td>0.001135</td>\n",
       "      <td>1.937616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>unigrams + bigrams</td>\n",
       "      <td>2.568008</td>\n",
       "      <td>86.491253</td>\n",
       "      <td>90.042289</td>\n",
       "      <td>1.282587</td>\n",
       "      <td>0.345635</td>\n",
       "      <td>0.357131</td>\n",
       "      <td>0.299086</td>\n",
       "      <td>0.369417</td>\n",
       "      <td>0.473809</td>\n",
       "      <td>0.357328</td>\n",
       "      <td>0.344037</td>\n",
       "      <td>0.495246</td>\n",
       "      <td>0.003739</td>\n",
       "      <td>4.603172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>bigrams + trigrams</td>\n",
       "      <td>3.062113</td>\n",
       "      <td>192.459998</td>\n",
       "      <td>196.059562</td>\n",
       "      <td>1.182285</td>\n",
       "      <td>0.007724</td>\n",
       "      <td>0.008295</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>0.008956</td>\n",
       "      <td>0.010589</td>\n",
       "      <td>0.008317</td>\n",
       "      <td>0.005288</td>\n",
       "      <td>0.290055</td>\n",
       "      <td>0.001203</td>\n",
       "      <td>1.917161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23</td>\n",
       "      <td>unigrams + bigrams + trigrams</td>\n",
       "      <td>3.952417</td>\n",
       "      <td>202.907462</td>\n",
       "      <td>207.441253</td>\n",
       "      <td>1.231872</td>\n",
       "      <td>0.277614</td>\n",
       "      <td>0.292436</td>\n",
       "      <td>0.224648</td>\n",
       "      <td>0.308931</td>\n",
       "      <td>0.380563</td>\n",
       "      <td>0.292854</td>\n",
       "      <td>0.275849</td>\n",
       "      <td>0.450947</td>\n",
       "      <td>0.002960</td>\n",
       "      <td>3.888559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ExperimentID                 ExperimentName  PreprocessorSpent  \\\n",
       "0            18                       unigrams           0.772241   \n",
       "1            19                        bigrams           3.341415   \n",
       "2            20                       trigrams           2.569367   \n",
       "3            21             unigrams + bigrams           2.568008   \n",
       "4            22             bigrams + trigrams           3.062113   \n",
       "5            23  unigrams + bigrams + trigrams           3.952417   \n",
       "\n",
       "   MethodSpent  TotalSpent   entropy  homogeneity  v_measure  adj_rand_index  \\\n",
       "0    12.209883   13.228796  1.312428     0.435405   0.444882        0.399010   \n",
       "1    38.889921   42.808480  1.129509     0.009562   0.010485        0.002215   \n",
       "2    55.094876   58.202433  0.901741     0.023336   0.028152        0.000420   \n",
       "3    86.491253   90.042289  1.282587     0.345635   0.357131        0.299086   \n",
       "4   192.459998  196.059562  1.182285     0.007724   0.008295        0.000358   \n",
       "5   202.907462  207.441253  1.231872     0.277614   0.292436        0.224648   \n",
       "\n",
       "   completeness  mutual_info_score  normalized_mutual_info_score  \\\n",
       "0      0.454781           0.596867                      0.444987   \n",
       "1      0.011605           0.013108                      0.010534   \n",
       "2      0.035475           0.031989                      0.028772   \n",
       "3      0.369417           0.473809                      0.357328   \n",
       "4      0.008956           0.010589                      0.008317   \n",
       "5      0.308931           0.380563                      0.292854   \n",
       "\n",
       "   adjusted_mutual_info_score  fowlkes_mallows_score  silhouette_coefficient  \\\n",
       "0                    0.434026               0.561498                0.006384   \n",
       "1                    0.007128               0.303138                0.001341   \n",
       "2                    0.020886               0.341644                0.001135   \n",
       "3                    0.344037               0.495246                0.003739   \n",
       "4                    0.005288               0.290055                0.001203   \n",
       "5                    0.275849               0.450947                0.002960   \n",
       "\n",
       "   calinski_harabaz_score  \n",
       "0                7.005031  \n",
       "1                2.086874  \n",
       "2                1.937616  \n",
       "3                4.603172  \n",
       "4                1.917161  \n",
       "5                3.888559  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords_ngrams.compute_scores(['silhouette_coefficient', 'calinski_harabaz_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "SCORES = [\n",
    "    'homogeneity', 'completeness', 'v_measure',\n",
    "    'adj_rand_index', 'adjusted_mutual_info_score',\n",
    "    'fowlkes_mallows_score',\n",
    "    'silhouette_coefficient', 'calinski_harabaz_score'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs4AAALICAYAAABvtXYxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11358e890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stopwords_ngrams.plot_scores(SCORES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "check_stopwords_ngrams = MultiClusteringExperiment(\n",
    "    data=dataset.data,\n",
    "    experiments=experiments,\n",
    "    verbose_name='Stopwords removed or not with different N-grams'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running multi experiment consisting of 4 sub experiments\n",
      "\n",
      "--------------------------------------------------\n",
      "*****Experiment #0*****\n",
      "Running experiment \"stopwords removed unigrams (id=24)\"...\n",
      "Running preprocessing...\n",
      "Step #0: PreprocessStep (id=18): finished in 0.77862906456 sec\n",
      "Finished preprocessing in 0.77862906456\n",
      "Running in-middle prepare function...\n",
      "Finished in-middle prepare function in 0.151027917862 sec\n",
      "Running method...\n",
      "Finished method in 2.19038820267 sec\n",
      "Finished experiment in 3.12004518509 sec\n",
      "\n",
      "--------------------------------------------------\n",
      "*****Experiment #1*****\n",
      "Running experiment \"with stopwords unigrams (id=25)\"...\n",
      "Running preprocessing...\n",
      "Step #0: PreprocessStep (id=19): finished in 0.917279005051 sec\n",
      "Finished preprocessing in 0.917279005051\n",
      "Running in-middle prepare function...\n",
      "Finished in-middle prepare function in 0.273751974106 sec\n",
      "Running method...\n",
      "Finished method in 1.73744320869 sec\n",
      "Finished experiment in 2.92847418785 sec\n",
      "\n",
      "--------------------------------------------------\n",
      "*****Experiment #2*****\n",
      "Running experiment \"stopwords removed unigrams + bigrams (id=26)\"...\n",
      "Running preprocessing...\n",
      "Step #0: PreprocessStep (id=20): finished in 2.49025297165 sec\n",
      "Finished preprocessing in 2.49025297165\n",
      "Running in-middle prepare function...\n",
      "Finished in-middle prepare function in 0.302216053009 sec\n",
      "Running method...\n",
      "Finished method in 11.6507668495 sec\n",
      "Finished experiment in 14.4432358742 sec\n",
      "\n",
      "--------------------------------------------------\n",
      "*****Experiment #3*****\n",
      "Running experiment \"with stopwords unigrams + bigrams (id=27)\"...\n",
      "Running preprocessing...\n",
      "Step #0: PreprocessStep (id=21): finished in 3.2871940136 sec\n",
      "Finished preprocessing in 3.2871940136\n",
      "Running in-middle prepare function...\n",
      "Finished in-middle prepare function in 1.00756597519 sec\n",
      "Running method...\n",
      "Finished method in 19.4914140701 sec\n",
      "Finished experiment in 23.7861740589 sec\n",
      "Finished multi experiment in 44.277929306 sec\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <center>\n",
       "        <h1> Multi Experiment Stopwords removed or not with different N-grams </h1><br>\n",
       "        <h2>Summary</h2>:\n",
       "        </center>\n",
       "        <b>Experiments</b>:<br>\n",
       "        <ul><li>stopwords removed unigrams (id=24)</li><li>with stopwords unigrams (id=25)</li><li>stopwords removed unigrams + bigrams (id=26)</li><li>with stopwords unigrams + bigrams (id=27)</li></ul>\n",
       "\n",
       "<br><br>Computed scores:<br><br><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ExperimentID</th>\n",
       "      <th>ExperimentName</th>\n",
       "      <th>PreprocessorSpent</th>\n",
       "      <th>MethodSpent</th>\n",
       "      <th>TotalSpent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>stopwords removed unigrams</td>\n",
       "      <td>0.778629</td>\n",
       "      <td>2.190388</td>\n",
       "      <td>3.120045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>with stopwords unigrams</td>\n",
       "      <td>0.917279</td>\n",
       "      <td>1.737443</td>\n",
       "      <td>2.928474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>stopwords removed unigrams + bigrams</td>\n",
       "      <td>2.490253</td>\n",
       "      <td>11.650767</td>\n",
       "      <td>14.443236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>with stopwords unigrams + bigrams</td>\n",
       "      <td>3.287194</td>\n",
       "      <td>19.491414</td>\n",
       "      <td>23.786174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "\n",
       "            Multi Experiment Stopwords removed or not with different N-grams.\n",
       "\n",
       "            Experiments:\n",
       "\n",
       "\n",
       "        \n",
       "\n",
       "\n",
       "\n",
       "Scores:\n",
       "\n",
       "   ExperimentID                        ExperimentName  PreprocessorSpent  \\\n",
       "0            24            stopwords removed unigrams           0.778629   \n",
       "1            25               with stopwords unigrams           0.917279   \n",
       "2            26  stopwords removed unigrams + bigrams           2.490253   \n",
       "3            27     with stopwords unigrams + bigrams           3.287194   \n",
       "\n",
       "   MethodSpent  TotalSpent  \n",
       "0     2.190388    3.120045  \n",
       "1     1.737443    2.928474  \n",
       "2    11.650767   14.443236  \n",
       "3    19.491414   23.786174  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_stopwords_ngrams.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ExperimentID</th>\n",
       "      <th>ExperimentName</th>\n",
       "      <th>PreprocessorSpent</th>\n",
       "      <th>MethodSpent</th>\n",
       "      <th>TotalSpent</th>\n",
       "      <th>entropy</th>\n",
       "      <th>homogeneity</th>\n",
       "      <th>v_measure</th>\n",
       "      <th>adj_rand_index</th>\n",
       "      <th>completeness</th>\n",
       "      <th>mutual_info_score</th>\n",
       "      <th>normalized_mutual_info_score</th>\n",
       "      <th>adjusted_mutual_info_score</th>\n",
       "      <th>fowlkes_mallows_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>stopwords removed unigrams</td>\n",
       "      <td>0.778629</td>\n",
       "      <td>2.190388</td>\n",
       "      <td>3.120045</td>\n",
       "      <td>1.312428</td>\n",
       "      <td>0.435405</td>\n",
       "      <td>0.444882</td>\n",
       "      <td>0.399010</td>\n",
       "      <td>0.454781</td>\n",
       "      <td>0.596867</td>\n",
       "      <td>0.444987</td>\n",
       "      <td>0.434026</td>\n",
       "      <td>0.561498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>with stopwords unigrams</td>\n",
       "      <td>0.917279</td>\n",
       "      <td>1.737443</td>\n",
       "      <td>2.928474</td>\n",
       "      <td>1.282442</td>\n",
       "      <td>0.263316</td>\n",
       "      <td>0.272088</td>\n",
       "      <td>0.239043</td>\n",
       "      <td>0.281465</td>\n",
       "      <td>0.360962</td>\n",
       "      <td>0.272239</td>\n",
       "      <td>0.261517</td>\n",
       "      <td>0.451536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>stopwords removed unigrams + bigrams</td>\n",
       "      <td>2.490253</td>\n",
       "      <td>11.650767</td>\n",
       "      <td>14.443236</td>\n",
       "      <td>1.282587</td>\n",
       "      <td>0.345635</td>\n",
       "      <td>0.357131</td>\n",
       "      <td>0.299086</td>\n",
       "      <td>0.369417</td>\n",
       "      <td>0.473809</td>\n",
       "      <td>0.357328</td>\n",
       "      <td>0.344037</td>\n",
       "      <td>0.495246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>with stopwords unigrams + bigrams</td>\n",
       "      <td>3.287194</td>\n",
       "      <td>19.491414</td>\n",
       "      <td>23.786174</td>\n",
       "      <td>1.199978</td>\n",
       "      <td>0.239637</td>\n",
       "      <td>0.255563</td>\n",
       "      <td>0.187564</td>\n",
       "      <td>0.273757</td>\n",
       "      <td>0.328503</td>\n",
       "      <td>0.256130</td>\n",
       "      <td>0.237778</td>\n",
       "      <td>0.430654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ExperimentID                        ExperimentName  PreprocessorSpent  \\\n",
       "0            24            stopwords removed unigrams           0.778629   \n",
       "1            25               with stopwords unigrams           0.917279   \n",
       "2            26  stopwords removed unigrams + bigrams           2.490253   \n",
       "3            27     with stopwords unigrams + bigrams           3.287194   \n",
       "\n",
       "   MethodSpent  TotalSpent   entropy  homogeneity  v_measure  adj_rand_index  \\\n",
       "0     2.190388    3.120045  1.312428     0.435405   0.444882        0.399010   \n",
       "1     1.737443    2.928474  1.282442     0.263316   0.272088        0.239043   \n",
       "2    11.650767   14.443236  1.282587     0.345635   0.357131        0.299086   \n",
       "3    19.491414   23.786174  1.199978     0.239637   0.255563        0.187564   \n",
       "\n",
       "   completeness  mutual_info_score  normalized_mutual_info_score  \\\n",
       "0      0.454781           0.596867                      0.444987   \n",
       "1      0.281465           0.360962                      0.272239   \n",
       "2      0.369417           0.473809                      0.357328   \n",
       "3      0.273757           0.328503                      0.256130   \n",
       "\n",
       "   adjusted_mutual_info_score  fowlkes_mallows_score  \n",
       "0                    0.434026               0.561498  \n",
       "1                    0.261517               0.451536  \n",
       "2                    0.344037               0.495246  \n",
       "3                    0.237778               0.430654  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_stopwords_ngrams.set_true_labels(labels)\n",
    "check_stopwords_ngrams.compute_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ExperimentID</th>\n",
       "      <th>ExperimentName</th>\n",
       "      <th>PreprocessorSpent</th>\n",
       "      <th>MethodSpent</th>\n",
       "      <th>TotalSpent</th>\n",
       "      <th>entropy</th>\n",
       "      <th>homogeneity</th>\n",
       "      <th>v_measure</th>\n",
       "      <th>adj_rand_index</th>\n",
       "      <th>completeness</th>\n",
       "      <th>mutual_info_score</th>\n",
       "      <th>normalized_mutual_info_score</th>\n",
       "      <th>adjusted_mutual_info_score</th>\n",
       "      <th>fowlkes_mallows_score</th>\n",
       "      <th>silhouette_coefficient</th>\n",
       "      <th>calinski_harabaz_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>stopwords removed unigrams</td>\n",
       "      <td>0.778629</td>\n",
       "      <td>2.190388</td>\n",
       "      <td>3.120045</td>\n",
       "      <td>1.312428</td>\n",
       "      <td>0.435405</td>\n",
       "      <td>0.444882</td>\n",
       "      <td>0.399010</td>\n",
       "      <td>0.454781</td>\n",
       "      <td>0.596867</td>\n",
       "      <td>0.444987</td>\n",
       "      <td>0.434026</td>\n",
       "      <td>0.561498</td>\n",
       "      <td>0.006384</td>\n",
       "      <td>7.005031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>with stopwords unigrams</td>\n",
       "      <td>0.917279</td>\n",
       "      <td>1.737443</td>\n",
       "      <td>2.928474</td>\n",
       "      <td>1.282442</td>\n",
       "      <td>0.263316</td>\n",
       "      <td>0.272088</td>\n",
       "      <td>0.239043</td>\n",
       "      <td>0.281465</td>\n",
       "      <td>0.360962</td>\n",
       "      <td>0.272239</td>\n",
       "      <td>0.261517</td>\n",
       "      <td>0.451536</td>\n",
       "      <td>0.001977</td>\n",
       "      <td>10.826097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>stopwords removed unigrams + bigrams</td>\n",
       "      <td>2.490253</td>\n",
       "      <td>11.650767</td>\n",
       "      <td>14.443236</td>\n",
       "      <td>1.282587</td>\n",
       "      <td>0.345635</td>\n",
       "      <td>0.357131</td>\n",
       "      <td>0.299086</td>\n",
       "      <td>0.369417</td>\n",
       "      <td>0.473809</td>\n",
       "      <td>0.357328</td>\n",
       "      <td>0.344037</td>\n",
       "      <td>0.495246</td>\n",
       "      <td>0.003739</td>\n",
       "      <td>4.603172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>with stopwords unigrams + bigrams</td>\n",
       "      <td>3.287194</td>\n",
       "      <td>19.491414</td>\n",
       "      <td>23.786174</td>\n",
       "      <td>1.199978</td>\n",
       "      <td>0.239637</td>\n",
       "      <td>0.255563</td>\n",
       "      <td>0.187564</td>\n",
       "      <td>0.273757</td>\n",
       "      <td>0.328503</td>\n",
       "      <td>0.256130</td>\n",
       "      <td>0.237778</td>\n",
       "      <td>0.430654</td>\n",
       "      <td>0.001818</td>\n",
       "      <td>6.714422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ExperimentID                        ExperimentName  PreprocessorSpent  \\\n",
       "0            24            stopwords removed unigrams           0.778629   \n",
       "1            25               with stopwords unigrams           0.917279   \n",
       "2            26  stopwords removed unigrams + bigrams           2.490253   \n",
       "3            27     with stopwords unigrams + bigrams           3.287194   \n",
       "\n",
       "   MethodSpent  TotalSpent   entropy  homogeneity  v_measure  adj_rand_index  \\\n",
       "0     2.190388    3.120045  1.312428     0.435405   0.444882        0.399010   \n",
       "1     1.737443    2.928474  1.282442     0.263316   0.272088        0.239043   \n",
       "2    11.650767   14.443236  1.282587     0.345635   0.357131        0.299086   \n",
       "3    19.491414   23.786174  1.199978     0.239637   0.255563        0.187564   \n",
       "\n",
       "   completeness  mutual_info_score  normalized_mutual_info_score  \\\n",
       "0      0.454781           0.596867                      0.444987   \n",
       "1      0.281465           0.360962                      0.272239   \n",
       "2      0.369417           0.473809                      0.357328   \n",
       "3      0.273757           0.328503                      0.256130   \n",
       "\n",
       "   adjusted_mutual_info_score  fowlkes_mallows_score  silhouette_coefficient  \\\n",
       "0                    0.434026               0.561498                0.006384   \n",
       "1                    0.261517               0.451536                0.001977   \n",
       "2                    0.344037               0.495246                0.003739   \n",
       "3                    0.237778               0.430654                0.001818   \n",
       "\n",
       "   calinski_harabaz_score  \n",
       "0                7.005031  \n",
       "1               10.826097  \n",
       "2                4.603172  \n",
       "3                6.714422  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_stopwords_ngrams.compute_scores(['silhouette_coefficient', 'calinski_harabaz_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>homogeneity</th>\n",
       "      <th>completeness</th>\n",
       "      <th>v_measure</th>\n",
       "      <th>adj_rand_index</th>\n",
       "      <th>adjusted_mutual_info_score</th>\n",
       "      <th>fowlkes_mallows_score</th>\n",
       "      <th>silhouette_coefficient</th>\n",
       "      <th>calinski_harabaz_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.435405</td>\n",
       "      <td>0.454781</td>\n",
       "      <td>0.444882</td>\n",
       "      <td>0.399010</td>\n",
       "      <td>0.434026</td>\n",
       "      <td>0.561498</td>\n",
       "      <td>0.006384</td>\n",
       "      <td>7.005031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.263316</td>\n",
       "      <td>0.281465</td>\n",
       "      <td>0.272088</td>\n",
       "      <td>0.239043</td>\n",
       "      <td>0.261517</td>\n",
       "      <td>0.451536</td>\n",
       "      <td>0.001977</td>\n",
       "      <td>10.826097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.345635</td>\n",
       "      <td>0.369417</td>\n",
       "      <td>0.357131</td>\n",
       "      <td>0.299086</td>\n",
       "      <td>0.344037</td>\n",
       "      <td>0.495246</td>\n",
       "      <td>0.003739</td>\n",
       "      <td>4.603172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.239637</td>\n",
       "      <td>0.273757</td>\n",
       "      <td>0.255563</td>\n",
       "      <td>0.187564</td>\n",
       "      <td>0.237778</td>\n",
       "      <td>0.430654</td>\n",
       "      <td>0.001818</td>\n",
       "      <td>6.714422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   homogeneity  completeness  v_measure  adj_rand_index  \\\n",
       "0     0.435405      0.454781   0.444882        0.399010   \n",
       "1     0.263316      0.281465   0.272088        0.239043   \n",
       "2     0.345635      0.369417   0.357131        0.299086   \n",
       "3     0.239637      0.273757   0.255563        0.187564   \n",
       "\n",
       "   adjusted_mutual_info_score  fowlkes_mallows_score  silhouette_coefficient  \\\n",
       "0                    0.434026               0.561498                0.006384   \n",
       "1                    0.261517               0.451536                0.001977   \n",
       "2                    0.344037               0.495246                0.003739   \n",
       "3                    0.237778               0.430654                0.001818   \n",
       "\n",
       "   calinski_harabaz_score  \n",
       "0                7.005031  \n",
       "1               10.826097  \n",
       "2                4.603172  \n",
       "3                6.714422  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_stopwords_ngrams.result[SCORES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "default_analyzer = TfidfVectorizer().build_analyzer()\n",
    "\n",
    "def stem_snowball(doc):\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    return (stemmer.stem(w) for w in default_analyzer(doc))\n",
    "\n",
    "def stem_lancaster(doc):\n",
    "    stemmer = LancasterStemmer()\n",
    "    return (stemmer.stem(w) for w in default_analyzer(doc))\n",
    "\n",
    "def lemmatizer(doc):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return (lemmatizer.lemmatize(w) for w in default_analyzer(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "experiments = [\n",
    "    ClusteringExperiment(\n",
    "        method=KMeansClusterer(\n",
    "            true_k,\n",
    "            distance=euclidean,\n",
    "            rng=Random(10),\n",
    "        ),\n",
    "        preprocessor=Preprocessor(\n",
    "            [TfidfVectorizer(\n",
    "                stop_words='english',\n",
    "                analyzer=stem_snowball,\n",
    "            ).as_preprocess_step()],\n",
    "        ),\n",
    "        prepare_func=lambda d: d.todense(),\n",
    "        verbose_name='snowball stemmer'\n",
    "    ),\n",
    "    ClusteringExperiment(\n",
    "        method=KMeansClusterer(\n",
    "            true_k,\n",
    "            distance=euclidean,\n",
    "            rng=Random(10),\n",
    "        ),\n",
    "        preprocessor=Preprocessor(\n",
    "            [TfidfVectorizer(\n",
    "                stop_words='english',\n",
    "                analyzer=stem_lancaster,\n",
    "            ).as_preprocess_step()],\n",
    "        ),\n",
    "        prepare_func=lambda d: d.todense(),\n",
    "        verbose_name='lancaster stemmer'\n",
    "    ),\n",
    "    ClusteringExperiment(\n",
    "        method=KMeansClusterer(\n",
    "            4,\n",
    "            distance=euclidean,\n",
    "            rng=Random(10),\n",
    "        ),\n",
    "        preprocessor=Preprocessor(\n",
    "            [TfidfVectorizer(\n",
    "                stop_words='english',\n",
    "                analyzer=lemmatizer, \n",
    "            ).as_preprocess_step()],\n",
    "        ),\n",
    "        prepare_func=lambda d: d.todense(),\n",
    "        verbose_name='lemmatizer'\n",
    "    ),\n",
    "    ClusteringExperiment(\n",
    "        method=KMeansClusterer(\n",
    "            4,\n",
    "            distance=euclidean,\n",
    "            rng=Random(10),\n",
    "        ),\n",
    "        preprocessor=Preprocessor(\n",
    "            [TfidfVectorizer(\n",
    "                stop_words='english',\n",
    "            ).as_preprocess_step()],\n",
    "        ),\n",
    "        prepare_func=lambda d: d.todense(),\n",
    "        verbose_name='without stem or lem'\n",
    "    )\n",
    "]\n",
    "stem_lem_exp = MultiClusteringExperiment(\n",
    "    data=dataset.data,\n",
    "    experiments=experiments,\n",
    "    verbose_name='Stemming and lemmatization'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running multi experiment consisting of 4 sub experiments\n",
      "\n",
      "--------------------------------------------------\n",
      "*****Experiment #0*****\n",
      "Running experiment \"snowball stemmer (id=32)\"...\n",
      "Running preprocessing...\n",
      "Step #0: PreprocessStep (id=26): finished in 11.9669880867 sec\n",
      "Finished preprocessing in 11.9669880867\n",
      "Running in-middle prepare function...\n",
      "Finished in-middle prepare function in 0.228842020035 sec\n",
      "Running method...\n",
      "Finished method in 10.3189949989 sec\n",
      "Finished experiment in 22.5148251057 sec\n",
      "\n",
      "--------------------------------------------------\n",
      "*****Experiment #1*****\n",
      "Running experiment \"lancaster stemmer (id=33)\"...\n",
      "Running preprocessing...\n",
      "Step #0: PreprocessStep (id=27): finished in 14.3874771595 sec\n",
      "Finished preprocessing in 14.3874771595\n",
      "Running in-middle prepare function...\n",
      "Finished in-middle prepare function in 0.19558596611 sec\n",
      "Running method...\n",
      "Finished method in 12.808065176 sec\n",
      "Finished experiment in 27.3911283016 sec\n",
      "\n",
      "--------------------------------------------------\n",
      "*****Experiment #2*****\n",
      "Running experiment \"lemmatizer (id=34)\"...\n",
      "Running preprocessing...\n",
      "Step #0: PreprocessStep (id=28): finished in 6.61851191521 sec\n",
      "Finished preprocessing in 6.61851191521\n",
      "Running in-middle prepare function...\n",
      "Finished in-middle prepare function in 0.257306098938 sec\n",
      "Running method...\n",
      "Finished method in 14.6359920502 sec\n",
      "Finished experiment in 21.5118100643 sec\n",
      "\n",
      "--------------------------------------------------\n",
      "*****Experiment #3*****\n",
      "Running experiment \"without stem or lem (id=35)\"...\n",
      "Running preprocessing...\n",
      "Step #0: PreprocessStep (id=29): finished in 0.875319004059 sec\n",
      "Finished preprocessing in 0.875319004059\n",
      "Running in-middle prepare function...\n",
      "Finished in-middle prepare function in 0.220818996429 sec\n",
      "Running method...\n",
      "Finished method in 9.19766402245 sec\n",
      "Finished experiment in 10.2938020229 sec\n",
      "Finished multi experiment in 81.7115654945 sec\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <center>\n",
       "        <h1> Multi Experiment Stemming and lemmatization </h1><br>\n",
       "        <h2>Summary</h2>:\n",
       "        </center>\n",
       "        <b>Experiments</b>:<br>\n",
       "        <ul><li>snowball stemmer (id=32)</li><li>lancaster stemmer (id=33)</li><li>lemmatizer (id=34)</li><li>without stem or lem (id=35)</li></ul>\n",
       "\n",
       "<br><br>Computed scores:<br><br><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ExperimentID</th>\n",
       "      <th>ExperimentName</th>\n",
       "      <th>PreprocessorSpent</th>\n",
       "      <th>MethodSpent</th>\n",
       "      <th>TotalSpent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>snowball stemmer</td>\n",
       "      <td>11.966988</td>\n",
       "      <td>10.318995</td>\n",
       "      <td>22.514825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>lancaster stemmer</td>\n",
       "      <td>14.387477</td>\n",
       "      <td>12.808065</td>\n",
       "      <td>27.391128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>lemmatizer</td>\n",
       "      <td>6.618512</td>\n",
       "      <td>14.635992</td>\n",
       "      <td>21.511810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>without stem or lem</td>\n",
       "      <td>0.875319</td>\n",
       "      <td>9.197664</td>\n",
       "      <td>10.293802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "\n",
       "            Multi Experiment Stemming and lemmatization.\n",
       "\n",
       "            Experiments:\n",
       "\n",
       "\n",
       "        \n",
       "\n",
       "\n",
       "\n",
       "Scores:\n",
       "\n",
       "   ExperimentID       ExperimentName  PreprocessorSpent  MethodSpent  \\\n",
       "0            32     snowball stemmer          11.966988    10.318995   \n",
       "1            33    lancaster stemmer          14.387477    12.808065   \n",
       "2            34           lemmatizer           6.618512    14.635992   \n",
       "3            35  without stem or lem           0.875319     9.197664   \n",
       "\n",
       "   TotalSpent  \n",
       "0   22.514825  \n",
       "1   27.391128  \n",
       "2   21.511810  \n",
       "3   10.293802  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_lem_exp.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ExperimentID</th>\n",
       "      <th>ExperimentName</th>\n",
       "      <th>PreprocessorSpent</th>\n",
       "      <th>MethodSpent</th>\n",
       "      <th>TotalSpent</th>\n",
       "      <th>entropy</th>\n",
       "      <th>homogeneity</th>\n",
       "      <th>v_measure</th>\n",
       "      <th>adj_rand_index</th>\n",
       "      <th>completeness</th>\n",
       "      <th>mutual_info_score</th>\n",
       "      <th>normalized_mutual_info_score</th>\n",
       "      <th>adjusted_mutual_info_score</th>\n",
       "      <th>fowlkes_mallows_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>snowball stemmer</td>\n",
       "      <td>11.966988</td>\n",
       "      <td>10.318995</td>\n",
       "      <td>22.514825</td>\n",
       "      <td>1.282177</td>\n",
       "      <td>0.268607</td>\n",
       "      <td>0.277583</td>\n",
       "      <td>0.240804</td>\n",
       "      <td>0.287180</td>\n",
       "      <td>0.368215</td>\n",
       "      <td>0.277738</td>\n",
       "      <td>0.266821</td>\n",
       "      <td>0.453232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>lancaster stemmer</td>\n",
       "      <td>14.387477</td>\n",
       "      <td>12.808065</td>\n",
       "      <td>27.391128</td>\n",
       "      <td>1.312402</td>\n",
       "      <td>0.312322</td>\n",
       "      <td>0.319124</td>\n",
       "      <td>0.287208</td>\n",
       "      <td>0.326228</td>\n",
       "      <td>0.428142</td>\n",
       "      <td>0.319200</td>\n",
       "      <td>0.310644</td>\n",
       "      <td>0.481822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>lemmatizer</td>\n",
       "      <td>6.618512</td>\n",
       "      <td>14.635992</td>\n",
       "      <td>21.511810</td>\n",
       "      <td>1.275477</td>\n",
       "      <td>0.264760</td>\n",
       "      <td>0.274300</td>\n",
       "      <td>0.237065</td>\n",
       "      <td>0.284554</td>\n",
       "      <td>0.362942</td>\n",
       "      <td>0.274479</td>\n",
       "      <td>0.262964</td>\n",
       "      <td>0.451812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>without stem or lem</td>\n",
       "      <td>0.875319</td>\n",
       "      <td>9.197664</td>\n",
       "      <td>10.293802</td>\n",
       "      <td>1.312428</td>\n",
       "      <td>0.435405</td>\n",
       "      <td>0.444882</td>\n",
       "      <td>0.399010</td>\n",
       "      <td>0.454781</td>\n",
       "      <td>0.596867</td>\n",
       "      <td>0.444987</td>\n",
       "      <td>0.434026</td>\n",
       "      <td>0.561498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ExperimentID       ExperimentName  PreprocessorSpent  MethodSpent  \\\n",
       "0            32     snowball stemmer          11.966988    10.318995   \n",
       "1            33    lancaster stemmer          14.387477    12.808065   \n",
       "2            34           lemmatizer           6.618512    14.635992   \n",
       "3            35  without stem or lem           0.875319     9.197664   \n",
       "\n",
       "   TotalSpent   entropy  homogeneity  v_measure  adj_rand_index  completeness  \\\n",
       "0   22.514825  1.282177     0.268607   0.277583        0.240804      0.287180   \n",
       "1   27.391128  1.312402     0.312322   0.319124        0.287208      0.326228   \n",
       "2   21.511810  1.275477     0.264760   0.274300        0.237065      0.284554   \n",
       "3   10.293802  1.312428     0.435405   0.444882        0.399010      0.454781   \n",
       "\n",
       "   mutual_info_score  normalized_mutual_info_score  \\\n",
       "0           0.368215                      0.277738   \n",
       "1           0.428142                      0.319200   \n",
       "2           0.362942                      0.274479   \n",
       "3           0.596867                      0.444987   \n",
       "\n",
       "   adjusted_mutual_info_score  fowlkes_mallows_score  \n",
       "0                    0.266821               0.453232  \n",
       "1                    0.310644               0.481822  \n",
       "2                    0.262964               0.451812  \n",
       "3                    0.434026               0.561498  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_lem_exp.set_true_labels(labels)\n",
    "stem_lem_exp.compute_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>homogeneity</th>\n",
       "      <th>completeness</th>\n",
       "      <th>v_measure</th>\n",
       "      <th>adj_rand_index</th>\n",
       "      <th>adjusted_mutual_info_score</th>\n",
       "      <th>fowlkes_mallows_score</th>\n",
       "      <th>silhouette_coefficient</th>\n",
       "      <th>calinski_harabaz_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.268607</td>\n",
       "      <td>0.287180</td>\n",
       "      <td>0.277583</td>\n",
       "      <td>0.240804</td>\n",
       "      <td>0.266821</td>\n",
       "      <td>0.453232</td>\n",
       "      <td>0.001601</td>\n",
       "      <td>11.832925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.312322</td>\n",
       "      <td>0.326228</td>\n",
       "      <td>0.319124</td>\n",
       "      <td>0.287208</td>\n",
       "      <td>0.310644</td>\n",
       "      <td>0.481822</td>\n",
       "      <td>-0.002438</td>\n",
       "      <td>12.946453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.264760</td>\n",
       "      <td>0.284554</td>\n",
       "      <td>0.274300</td>\n",
       "      <td>0.237065</td>\n",
       "      <td>0.262964</td>\n",
       "      <td>0.451812</td>\n",
       "      <td>0.000863</td>\n",
       "      <td>11.193703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.435405</td>\n",
       "      <td>0.454781</td>\n",
       "      <td>0.444882</td>\n",
       "      <td>0.399010</td>\n",
       "      <td>0.434026</td>\n",
       "      <td>0.561498</td>\n",
       "      <td>0.006384</td>\n",
       "      <td>7.005031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   homogeneity  completeness  v_measure  adj_rand_index  \\\n",
       "0     0.268607      0.287180   0.277583        0.240804   \n",
       "1     0.312322      0.326228   0.319124        0.287208   \n",
       "2     0.264760      0.284554   0.274300        0.237065   \n",
       "3     0.435405      0.454781   0.444882        0.399010   \n",
       "\n",
       "   adjusted_mutual_info_score  fowlkes_mallows_score  silhouette_coefficient  \\\n",
       "0                    0.266821               0.453232                0.001601   \n",
       "1                    0.310644               0.481822               -0.002438   \n",
       "2                    0.262964               0.451812                0.000863   \n",
       "3                    0.434026               0.561498                0.006384   \n",
       "\n",
       "   calinski_harabaz_score  \n",
       "0               11.832925  \n",
       "1               12.946453  \n",
       "2               11.193703  \n",
       "3                7.005031  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_lem_exp.compute_scores(['silhouette_coefficient', 'calinski_harabaz_score'])\n",
    "stem_lem_exp.result[SCORES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1353, 20654)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_lem_exp.experiments[0].preprocessed_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1353, 20654)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_lem_exp.experiments[0].preprocessed_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "experiments = [\n",
    "    ClusteringExperiment(\n",
    "        method=KMeansClusterer(\n",
    "            true_k,\n",
    "            distance=euclidean,\n",
    "            rng=Random(15)\n",
    "        ),\n",
    "        preprocessor=Preprocessor(\n",
    "            [TfidfVectorizer(\n",
    "                stop_words='english', max_df=0.5, min_df=2\n",
    "            ).as_preprocess_step()],\n",
    "        ),\n",
    "        prepare_func=lambda d: d.todense(),\n",
    "        verbose_name='max_df=0.5, min_df=2'\n",
    "    ),\n",
    "    ClusteringExperiment(\n",
    "        method=KMeansClusterer(\n",
    "            true_k,\n",
    "            distance=euclidean,\n",
    "            rng=Random(15)\n",
    "        ),\n",
    "        preprocessor=Preprocessor(\n",
    "            [TfidfVectorizer(\n",
    "                stop_words='english', max_df=0.5, min_df=4\n",
    "            ).as_preprocess_step()],\n",
    "        ),\n",
    "        prepare_func=lambda d: d.todense(),\n",
    "        verbose_name='max_df=0.5, min_df=4'\n",
    "    ),\n",
    "    ClusteringExperiment(\n",
    "        method=KMeansClusterer(\n",
    "            true_k,\n",
    "            distance=euclidean,\n",
    "            rng=Random(15)\n",
    "        ),\n",
    "        preprocessor=Preprocessor(\n",
    "            [TfidfVectorizer(\n",
    "                stop_words='english', max_df=0.7, min_df=2\n",
    "            ).as_preprocess_step()],\n",
    "        ),\n",
    "        prepare_func=lambda d: d.todense(),\n",
    "        verbose_name='max_df=0.7, min_df=2'\n",
    "    ),\n",
    "        ClusteringExperiment(\n",
    "        method=KMeansClusterer(\n",
    "            true_k,\n",
    "            distance=euclidean,\n",
    "            rng=Random(15),\n",
    "        ),\n",
    "        preprocessor=Preprocessor(\n",
    "            [TfidfVectorizer(\n",
    "                stop_words='english', max_df=0.7, min_df=4\n",
    "            ).as_preprocess_step()],\n",
    "        ),\n",
    "        prepare_func=lambda d: d.todense(),\n",
    "        verbose_name='max_df=0.7, min_df=4'\n",
    "    ),\n",
    "        ClusteringExperiment(\n",
    "        method=KMeansClusterer(\n",
    "            true_k,\n",
    "            distance=euclidean,\n",
    "            rng=Random(15),\n",
    "        ),\n",
    "        preprocessor=Preprocessor(\n",
    "            [TfidfVectorizer(\n",
    "                stop_words='english', max_df=0.7, min_df=6\n",
    "            ).as_preprocess_step()],\n",
    "        ),\n",
    "        prepare_func=lambda d: d.todense(),\n",
    "        verbose_name='max_df=0.7, min_df=6'\n",
    "    ),\n",
    "    ClusteringExperiment(\n",
    "        method=KMeansClusterer(\n",
    "            true_k,\n",
    "            distance=euclidean,\n",
    "            rng=Random(15),\n",
    "        ),\n",
    "        preprocessor=Preprocessor(\n",
    "            [TfidfVectorizer(\n",
    "                stop_words='english', max_df=0.9, min_df=6\n",
    "            ).as_preprocess_step()],\n",
    "        ),\n",
    "        prepare_func=lambda d: d.todense(),\n",
    "        verbose_name='max_df=0.9, min_df=6'\n",
    "    ),\n",
    "    ClusteringExperiment(\n",
    "        method=KMeansClusterer(\n",
    "            true_k,\n",
    "            distance=euclidean,\n",
    "            rng=Random(15),\n",
    "        ),\n",
    "        preprocessor=Preprocessor(\n",
    "            [TfidfVectorizer(\n",
    "                stop_words='english', max_df=0.9, min_df=10\n",
    "            ).as_preprocess_step()],\n",
    "        ),\n",
    "        prepare_func=lambda d: d.todense(),\n",
    "        verbose_name='max_df=0.9, min_df=10'\n",
    "    ),\n",
    "    ClusteringExperiment(\n",
    "        method=KMeansClusterer(\n",
    "            true_k,\n",
    "            distance=euclidean,\n",
    "            rng=Random(15),\n",
    "        ),\n",
    "        preprocessor=Preprocessor(\n",
    "            [TfidfVectorizer(\n",
    "                stop_words='english', max_df=0.7, min_df=0.1\n",
    "            ).as_preprocess_step()],\n",
    "        ),\n",
    "        prepare_func=lambda d: d.todense(),\n",
    "        verbose_name='max_df=0.7, min_df=0.1'\n",
    "    ),\n",
    "    ClusteringExperiment(\n",
    "        method=KMeansClusterer(\n",
    "            true_k,\n",
    "            distance=euclidean,\n",
    "            rng=Random(15),\n",
    "        ),\n",
    "        preprocessor=Preprocessor(\n",
    "            [TfidfVectorizer(\n",
    "                stop_words='english', max_df=0.7, min_df=0.05\n",
    "            ).as_preprocess_step()],\n",
    "        ),\n",
    "        prepare_func=lambda d: d.todense(),\n",
    "        verbose_name='max_df=0.7, min_df=0.05'\n",
    "    ),\n",
    "    ClusteringExperiment(\n",
    "        method=KMeansClusterer(\n",
    "            true_k,\n",
    "            distance=euclidean,\n",
    "            rng=Random(15),\n",
    "        ),\n",
    "        preprocessor=Preprocessor(\n",
    "            [TfidfVectorizer(\n",
    "                stop_words='english', max_df=0.7, min_df=0.01\n",
    "            ).as_preprocess_step()],\n",
    "        ),\n",
    "        prepare_func=lambda d: d.todense(),\n",
    "        verbose_name='max_df=0.7, min_df=0.01'\n",
    "    ),\n",
    "        ClusteringExperiment(\n",
    "        method=KMeansClusterer(\n",
    "            true_k,\n",
    "            distance=euclidean,\n",
    "            rng=Random(15),\n",
    "        ),\n",
    "        preprocessor=Preprocessor(\n",
    "            [TfidfVectorizer(\n",
    "                stop_words='english', max_df=0.8, min_df=0.005\n",
    "            ).as_preprocess_step()],\n",
    "        ),\n",
    "        prepare_func=lambda d: d.todense(),\n",
    "        verbose_name='max_df=0.8, min_df=0.005'\n",
    "    ),\n",
    "]\n",
    "tfidf_constraints = MultiClusteringExperiment(\n",
    "    data=dataset.data,\n",
    "    experiments=experiments,\n",
    "    verbose_name='Different df constraints'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running multi experiment consisting of 11 sub experiments\n",
      "\n",
      "--------------------------------------------------\n",
      "*****Experiment #0*****\n",
      "Running experiment \"max_df=0.5, min_df=2 (id=51)\"...\n",
      "Running preprocessing...\n",
      "Step #0: PreprocessStep (id=45): finished in 0.650729894638 sec\n",
      "Finished preprocessing in 0.650729894638\n",
      "Running in-middle prepare function...\n",
      "Finished in-middle prepare function in 0.167391061783 sec\n",
      "Running method...\n",
      "Finished method in 11.6344499588 sec\n",
      "Finished experiment in 12.4525709152 sec\n",
      "\n",
      "--------------------------------------------------\n",
      "*****Experiment #1*****\n",
      "Running experiment \"max_df=0.5, min_df=4 (id=52)\"...\n",
      "Running preprocessing...\n",
      "Step #0: PreprocessStep (id=46): finished in 0.640695810318 sec\n",
      "Finished preprocessing in 0.640695810318\n",
      "Running in-middle prepare function...\n",
      "Finished in-middle prepare function in 0.130686998367 sec\n",
      "Running method...\n",
      "Finished method in 7.24587988853 sec\n",
      "Finished experiment in 8.01726269722 sec\n",
      "\n",
      "--------------------------------------------------\n",
      "*****Experiment #2*****\n",
      "Running experiment \"max_df=0.7, min_df=2 (id=53)\"...\n",
      "Running preprocessing...\n",
      "Step #0: PreprocessStep (id=47): finished in 0.639949083328 sec\n",
      "Finished preprocessing in 0.639949083328\n",
      "Running in-middle prepare function...\n",
      "Finished in-middle prepare function in 0.0984830856323 sec\n",
      "Running method...\n",
      "Finished method in 10.7814810276 sec\n",
      "Finished experiment in 11.5199131966 sec\n",
      "\n",
      "--------------------------------------------------\n",
      "*****Experiment #3*****\n",
      "Running experiment \"max_df=0.7, min_df=4 (id=54)\"...\n",
      "Running preprocessing...\n",
      "Step #0: PreprocessStep (id=48): finished in 0.623355865479 sec\n",
      "Finished preprocessing in 0.623355865479\n",
      "Running in-middle prepare function...\n",
      "Finished in-middle prepare function in 0.0517990589142 sec\n",
      "Running method...\n",
      "Finished method in 4.37920618057 sec\n",
      "Finished experiment in 5.05436110497 sec\n",
      "\n",
      "--------------------------------------------------\n",
      "*****Experiment #4*****\n",
      "Running experiment \"max_df=0.7, min_df=6 (id=55)\"...\n",
      "Running preprocessing...\n",
      "Step #0: PreprocessStep (id=49): finished in 0.581367015839 sec\n",
      "Finished preprocessing in 0.581367015839\n",
      "Running in-middle prepare function...\n",
      "Finished in-middle prepare function in 0.0411319732666 sec\n",
      "Running method...\n",
      "Finished method in 3.90072798729 sec\n",
      "Finished experiment in 4.52322697639 sec\n",
      "\n",
      "--------------------------------------------------\n",
      "*****Experiment #5*****\n",
      "Running experiment \"max_df=0.9, min_df=6 (id=56)\"...\n",
      "Running preprocessing...\n",
      "Step #0: PreprocessStep (id=50): finished in 0.548573970795 sec\n",
      "Finished preprocessing in 0.548573970795\n",
      "Running in-middle prepare function...\n",
      "Finished in-middle prepare function in 0.0465931892395 sec\n",
      "Running method...\n",
      "Finished method in 3.05203008652 sec\n",
      "Finished experiment in 3.64719724655 sec\n",
      "\n",
      "--------------------------------------------------\n",
      "*****Experiment #6*****\n",
      "Running experiment \"max_df=0.9, min_df=10 (id=57)\"...\n",
      "Running preprocessing...\n",
      "Step #0: PreprocessStep (id=51): finished in 0.644423961639 sec\n",
      "Finished preprocessing in 0.644423961639\n",
      "Running in-middle prepare function...\n",
      "Finished in-middle prepare function in 0.0384788513184 sec\n",
      "Running method...\n",
      "Finished method in 4.36696386337 sec\n",
      "Finished experiment in 5.04986667633 sec\n",
      "\n",
      "--------------------------------------------------\n",
      "*****Experiment #7*****\n",
      "Running experiment \"max_df=0.7, min_df=0.1 (id=58)\"...\n",
      "Running preprocessing...\n",
      "Step #0: PreprocessStep (id=52): finished in 0.790027856827 sec\n",
      "Finished preprocessing in 0.790027856827\n",
      "Running in-middle prepare function...\n",
      "Finished in-middle prepare function in 0.0042929649353 sec\n",
      "Running method...\n",
      "Finished method in 1.81114697456 sec\n",
      "Finished experiment in 2.60546779633 sec\n",
      "\n",
      "--------------------------------------------------\n",
      "*****Experiment #8*****\n",
      "Running experiment \"max_df=0.7, min_df=0.05 (id=59)\"...\n",
      "Running preprocessing...\n",
      "Step #0: PreprocessStep (id=53): finished in 0.713892936707 sec\n",
      "Finished preprocessing in 0.713892936707\n",
      "Running in-middle prepare function...\n",
      "Finished in-middle prepare function in 0.00324511528015 sec\n",
      "Running method...\n",
      "Finished method in 2.87566494942 sec\n",
      "Finished experiment in 3.5928030014 sec\n",
      "\n",
      "--------------------------------------------------\n",
      "*****Experiment #9*****\n",
      "Running experiment \"max_df=0.7, min_df=0.01 (id=60)\"...\n",
      "Running preprocessing...\n",
      "Step #0: PreprocessStep (id=54): finished in 0.643371105194 sec\n",
      "Finished preprocessing in 0.643371105194\n",
      "Running in-middle prepare function...\n",
      "Finished in-middle prepare function in 0.0240001678467 sec\n",
      "Running method...\n",
      "Finished method in 5.58499288559 sec\n",
      "Finished experiment in 6.25236415863 sec\n",
      "\n",
      "--------------------------------------------------\n",
      "*****Experiment #10*****\n",
      "Running experiment \"max_df=0.8, min_df=0.005 (id=61)\"...\n",
      "Running preprocessing...\n",
      "Step #0: PreprocessStep (id=55): finished in 0.597946882248 sec\n",
      "Finished preprocessing in 0.597946882248\n",
      "Running in-middle prepare function...\n",
      "Finished in-middle prepare function in 0.0584619045258 sec\n",
      "Running method...\n",
      "Finished method in 3.735435009 sec\n",
      "Finished experiment in 4.39184379578 sec\n",
      "Finished multi experiment in 67.1068775654 sec\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <center>\n",
       "        <h1> Multi Experiment Different df constraints </h1><br>\n",
       "        <h2>Summary</h2>:\n",
       "        </center>\n",
       "        <b>Experiments</b>:<br>\n",
       "        <ul><li>max_df=0.5, min_df=2 (id=51)</li><li>max_df=0.5, min_df=4 (id=52)</li><li>max_df=0.7, min_df=2 (id=53)</li><li>max_df=0.7, min_df=4 (id=54)</li><li>max_df=0.7, min_df=6 (id=55)</li><li>max_df=0.9, min_df=6 (id=56)</li><li>max_df=0.9, min_df=10 (id=57)</li><li>max_df=0.7, min_df=0.1 (id=58)</li><li>max_df=0.7, min_df=0.05 (id=59)</li><li>max_df=0.7, min_df=0.01 (id=60)</li><li>max_df=0.8, min_df=0.005 (id=61)</li></ul>\n",
       "\n",
       "<br><br>Computed scores:<br><br><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ExperimentID</th>\n",
       "      <th>ExperimentName</th>\n",
       "      <th>PreprocessorSpent</th>\n",
       "      <th>MethodSpent</th>\n",
       "      <th>TotalSpent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51</td>\n",
       "      <td>max_df=0.5, min_df=2</td>\n",
       "      <td>0.650730</td>\n",
       "      <td>11.634450</td>\n",
       "      <td>12.452571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52</td>\n",
       "      <td>max_df=0.5, min_df=4</td>\n",
       "      <td>0.640696</td>\n",
       "      <td>7.245880</td>\n",
       "      <td>8.017263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53</td>\n",
       "      <td>max_df=0.7, min_df=2</td>\n",
       "      <td>0.639949</td>\n",
       "      <td>10.781481</td>\n",
       "      <td>11.519913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>max_df=0.7, min_df=4</td>\n",
       "      <td>0.623356</td>\n",
       "      <td>4.379206</td>\n",
       "      <td>5.054361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55</td>\n",
       "      <td>max_df=0.7, min_df=6</td>\n",
       "      <td>0.581367</td>\n",
       "      <td>3.900728</td>\n",
       "      <td>4.523227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>56</td>\n",
       "      <td>max_df=0.9, min_df=6</td>\n",
       "      <td>0.548574</td>\n",
       "      <td>3.052030</td>\n",
       "      <td>3.647197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>57</td>\n",
       "      <td>max_df=0.9, min_df=10</td>\n",
       "      <td>0.644424</td>\n",
       "      <td>4.366964</td>\n",
       "      <td>5.049867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>58</td>\n",
       "      <td>max_df=0.7, min_df=0.1</td>\n",
       "      <td>0.790028</td>\n",
       "      <td>1.811147</td>\n",
       "      <td>2.605468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>59</td>\n",
       "      <td>max_df=0.7, min_df=0.05</td>\n",
       "      <td>0.713893</td>\n",
       "      <td>2.875665</td>\n",
       "      <td>3.592803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>60</td>\n",
       "      <td>max_df=0.7, min_df=0.01</td>\n",
       "      <td>0.643371</td>\n",
       "      <td>5.584993</td>\n",
       "      <td>6.252364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>61</td>\n",
       "      <td>max_df=0.8, min_df=0.005</td>\n",
       "      <td>0.597947</td>\n",
       "      <td>3.735435</td>\n",
       "      <td>4.391844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "\n",
       "            Multi Experiment Different df constraints.\n",
       "\n",
       "            Experiments:\n",
       "\n",
       "\n",
       "        \n",
       "\n",
       "\n",
       "\n",
       "Scores:\n",
       "\n",
       "    ExperimentID            ExperimentName  PreprocessorSpent  MethodSpent  \\\n",
       "0             51      max_df=0.5, min_df=2           0.650730    11.634450   \n",
       "1             52      max_df=0.5, min_df=4           0.640696     7.245880   \n",
       "2             53      max_df=0.7, min_df=2           0.639949    10.781481   \n",
       "3             54      max_df=0.7, min_df=4           0.623356     4.379206   \n",
       "4             55      max_df=0.7, min_df=6           0.581367     3.900728   \n",
       "5             56      max_df=0.9, min_df=6           0.548574     3.052030   \n",
       "6             57     max_df=0.9, min_df=10           0.644424     4.366964   \n",
       "7             58    max_df=0.7, min_df=0.1           0.790028     1.811147   \n",
       "8             59   max_df=0.7, min_df=0.05           0.713893     2.875665   \n",
       "9             60   max_df=0.7, min_df=0.01           0.643371     5.584993   \n",
       "10            61  max_df=0.8, min_df=0.005           0.597947     3.735435   \n",
       "\n",
       "    TotalSpent  \n",
       "0    12.452571  \n",
       "1     8.017263  \n",
       "2    11.519913  \n",
       "3     5.054361  \n",
       "4     4.523227  \n",
       "5     3.647197  \n",
       "6     5.049867  \n",
       "7     2.605468  \n",
       "8     3.592803  \n",
       "9     6.252364  \n",
       "10    4.391844  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_constraints.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ExperimentID</th>\n",
       "      <th>ExperimentName</th>\n",
       "      <th>PreprocessorSpent</th>\n",
       "      <th>MethodSpent</th>\n",
       "      <th>TotalSpent</th>\n",
       "      <th>entropy</th>\n",
       "      <th>homogeneity</th>\n",
       "      <th>v_measure</th>\n",
       "      <th>adj_rand_index</th>\n",
       "      <th>completeness</th>\n",
       "      <th>mutual_info_score</th>\n",
       "      <th>normalized_mutual_info_score</th>\n",
       "      <th>adjusted_mutual_info_score</th>\n",
       "      <th>fowlkes_mallows_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51</td>\n",
       "      <td>max_df=0.5, min_df=2</td>\n",
       "      <td>0.650730</td>\n",
       "      <td>11.634450</td>\n",
       "      <td>12.452571</td>\n",
       "      <td>1.341422</td>\n",
       "      <td>0.453964</td>\n",
       "      <td>0.458886</td>\n",
       "      <td>0.320744</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>0.622309</td>\n",
       "      <td>0.458913</td>\n",
       "      <td>0.452631</td>\n",
       "      <td>0.500960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52</td>\n",
       "      <td>max_df=0.5, min_df=4</td>\n",
       "      <td>0.640696</td>\n",
       "      <td>7.245880</td>\n",
       "      <td>8.017263</td>\n",
       "      <td>1.356228</td>\n",
       "      <td>0.513437</td>\n",
       "      <td>0.516187</td>\n",
       "      <td>0.447966</td>\n",
       "      <td>0.518966</td>\n",
       "      <td>0.703837</td>\n",
       "      <td>0.516194</td>\n",
       "      <td>0.512249</td>\n",
       "      <td>0.591984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53</td>\n",
       "      <td>max_df=0.7, min_df=2</td>\n",
       "      <td>0.639949</td>\n",
       "      <td>10.781481</td>\n",
       "      <td>11.519913</td>\n",
       "      <td>1.344950</td>\n",
       "      <td>0.466276</td>\n",
       "      <td>0.470721</td>\n",
       "      <td>0.337562</td>\n",
       "      <td>0.475250</td>\n",
       "      <td>0.639188</td>\n",
       "      <td>0.470742</td>\n",
       "      <td>0.464974</td>\n",
       "      <td>0.512518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>max_df=0.7, min_df=4</td>\n",
       "      <td>0.623356</td>\n",
       "      <td>4.379206</td>\n",
       "      <td>5.054361</td>\n",
       "      <td>1.363101</td>\n",
       "      <td>0.515593</td>\n",
       "      <td>0.517051</td>\n",
       "      <td>0.438837</td>\n",
       "      <td>0.518518</td>\n",
       "      <td>0.706793</td>\n",
       "      <td>0.517054</td>\n",
       "      <td>0.514411</td>\n",
       "      <td>0.584265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55</td>\n",
       "      <td>max_df=0.7, min_df=6</td>\n",
       "      <td>0.581367</td>\n",
       "      <td>3.900728</td>\n",
       "      <td>4.523227</td>\n",
       "      <td>1.369378</td>\n",
       "      <td>0.527135</td>\n",
       "      <td>0.527415</td>\n",
       "      <td>0.457742</td>\n",
       "      <td>0.527695</td>\n",
       "      <td>0.722614</td>\n",
       "      <td>0.527415</td>\n",
       "      <td>0.525981</td>\n",
       "      <td>0.597396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>56</td>\n",
       "      <td>max_df=0.9, min_df=6</td>\n",
       "      <td>0.548574</td>\n",
       "      <td>3.052030</td>\n",
       "      <td>3.647197</td>\n",
       "      <td>1.340179</td>\n",
       "      <td>0.464370</td>\n",
       "      <td>0.469621</td>\n",
       "      <td>0.351587</td>\n",
       "      <td>0.474992</td>\n",
       "      <td>0.636574</td>\n",
       "      <td>0.469651</td>\n",
       "      <td>0.463063</td>\n",
       "      <td>0.524046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>57</td>\n",
       "      <td>max_df=0.9, min_df=10</td>\n",
       "      <td>0.644424</td>\n",
       "      <td>4.366964</td>\n",
       "      <td>5.049867</td>\n",
       "      <td>1.329727</td>\n",
       "      <td>0.459944</td>\n",
       "      <td>0.466945</td>\n",
       "      <td>0.346807</td>\n",
       "      <td>0.474162</td>\n",
       "      <td>0.630506</td>\n",
       "      <td>0.466999</td>\n",
       "      <td>0.458625</td>\n",
       "      <td>0.522442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>58</td>\n",
       "      <td>max_df=0.7, min_df=0.1</td>\n",
       "      <td>0.790028</td>\n",
       "      <td>1.811147</td>\n",
       "      <td>2.605468</td>\n",
       "      <td>1.342582</td>\n",
       "      <td>0.232931</td>\n",
       "      <td>0.235356</td>\n",
       "      <td>0.213574</td>\n",
       "      <td>0.237832</td>\n",
       "      <td>0.319309</td>\n",
       "      <td>0.235369</td>\n",
       "      <td>0.231058</td>\n",
       "      <td>0.420720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>59</td>\n",
       "      <td>max_df=0.7, min_df=0.05</td>\n",
       "      <td>0.713893</td>\n",
       "      <td>2.875665</td>\n",
       "      <td>3.592803</td>\n",
       "      <td>1.298366</td>\n",
       "      <td>0.353540</td>\n",
       "      <td>0.363138</td>\n",
       "      <td>0.271594</td>\n",
       "      <td>0.373273</td>\n",
       "      <td>0.484645</td>\n",
       "      <td>0.363272</td>\n",
       "      <td>0.351961</td>\n",
       "      <td>0.471190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>60</td>\n",
       "      <td>max_df=0.7, min_df=0.01</td>\n",
       "      <td>0.643371</td>\n",
       "      <td>5.584993</td>\n",
       "      <td>6.252364</td>\n",
       "      <td>1.212222</td>\n",
       "      <td>0.482718</td>\n",
       "      <td>0.512359</td>\n",
       "      <td>0.433861</td>\n",
       "      <td>0.545879</td>\n",
       "      <td>0.661727</td>\n",
       "      <td>0.513328</td>\n",
       "      <td>0.481453</td>\n",
       "      <td>0.601968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>61</td>\n",
       "      <td>max_df=0.8, min_df=0.005</td>\n",
       "      <td>0.597947</td>\n",
       "      <td>3.735435</td>\n",
       "      <td>4.391844</td>\n",
       "      <td>1.334906</td>\n",
       "      <td>0.462009</td>\n",
       "      <td>0.468144</td>\n",
       "      <td>0.348477</td>\n",
       "      <td>0.474444</td>\n",
       "      <td>0.633338</td>\n",
       "      <td>0.468186</td>\n",
       "      <td>0.460696</td>\n",
       "      <td>0.522727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ExperimentID            ExperimentName  PreprocessorSpent  MethodSpent  \\\n",
       "0             51      max_df=0.5, min_df=2           0.650730    11.634450   \n",
       "1             52      max_df=0.5, min_df=4           0.640696     7.245880   \n",
       "2             53      max_df=0.7, min_df=2           0.639949    10.781481   \n",
       "3             54      max_df=0.7, min_df=4           0.623356     4.379206   \n",
       "4             55      max_df=0.7, min_df=6           0.581367     3.900728   \n",
       "5             56      max_df=0.9, min_df=6           0.548574     3.052030   \n",
       "6             57     max_df=0.9, min_df=10           0.644424     4.366964   \n",
       "7             58    max_df=0.7, min_df=0.1           0.790028     1.811147   \n",
       "8             59   max_df=0.7, min_df=0.05           0.713893     2.875665   \n",
       "9             60   max_df=0.7, min_df=0.01           0.643371     5.584993   \n",
       "10            61  max_df=0.8, min_df=0.005           0.597947     3.735435   \n",
       "\n",
       "    TotalSpent   entropy  homogeneity  v_measure  adj_rand_index  \\\n",
       "0    12.452571  1.341422     0.453964   0.458886        0.320744   \n",
       "1     8.017263  1.356228     0.513437   0.516187        0.447966   \n",
       "2    11.519913  1.344950     0.466276   0.470721        0.337562   \n",
       "3     5.054361  1.363101     0.515593   0.517051        0.438837   \n",
       "4     4.523227  1.369378     0.527135   0.527415        0.457742   \n",
       "5     3.647197  1.340179     0.464370   0.469621        0.351587   \n",
       "6     5.049867  1.329727     0.459944   0.466945        0.346807   \n",
       "7     2.605468  1.342582     0.232931   0.235356        0.213574   \n",
       "8     3.592803  1.298366     0.353540   0.363138        0.271594   \n",
       "9     6.252364  1.212222     0.482718   0.512359        0.433861   \n",
       "10    4.391844  1.334906     0.462009   0.468144        0.348477   \n",
       "\n",
       "    completeness  mutual_info_score  normalized_mutual_info_score  \\\n",
       "0       0.463917           0.622309                      0.458913   \n",
       "1       0.518966           0.703837                      0.516194   \n",
       "2       0.475250           0.639188                      0.470742   \n",
       "3       0.518518           0.706793                      0.517054   \n",
       "4       0.527695           0.722614                      0.527415   \n",
       "5       0.474992           0.636574                      0.469651   \n",
       "6       0.474162           0.630506                      0.466999   \n",
       "7       0.237832           0.319309                      0.235369   \n",
       "8       0.373273           0.484645                      0.363272   \n",
       "9       0.545879           0.661727                      0.513328   \n",
       "10      0.474444           0.633338                      0.468186   \n",
       "\n",
       "    adjusted_mutual_info_score  fowlkes_mallows_score  \n",
       "0                     0.452631               0.500960  \n",
       "1                     0.512249               0.591984  \n",
       "2                     0.464974               0.512518  \n",
       "3                     0.514411               0.584265  \n",
       "4                     0.525981               0.597396  \n",
       "5                     0.463063               0.524046  \n",
       "6                     0.458625               0.522442  \n",
       "7                     0.231058               0.420720  \n",
       "8                     0.351961               0.471190  \n",
       "9                     0.481453               0.601968  \n",
       "10                    0.460696               0.522727  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_constraints.set_true_labels(labels)\n",
    "tfidf_constraints.compute_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ExperimentName</th>\n",
       "      <th>homogeneity</th>\n",
       "      <th>completeness</th>\n",
       "      <th>v_measure</th>\n",
       "      <th>adj_rand_index</th>\n",
       "      <th>adjusted_mutual_info_score</th>\n",
       "      <th>fowlkes_mallows_score</th>\n",
       "      <th>silhouette_coefficient</th>\n",
       "      <th>calinski_harabaz_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max_df=0.5, min_df=2</td>\n",
       "      <td>0.453964</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>0.458886</td>\n",
       "      <td>0.320744</td>\n",
       "      <td>0.452631</td>\n",
       "      <td>0.500960</td>\n",
       "      <td>0.008181</td>\n",
       "      <td>7.822818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max_df=0.5, min_df=4</td>\n",
       "      <td>0.513437</td>\n",
       "      <td>0.518966</td>\n",
       "      <td>0.516187</td>\n",
       "      <td>0.447966</td>\n",
       "      <td>0.512249</td>\n",
       "      <td>0.591984</td>\n",
       "      <td>0.008774</td>\n",
       "      <td>8.664423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max_df=0.7, min_df=2</td>\n",
       "      <td>0.466276</td>\n",
       "      <td>0.475250</td>\n",
       "      <td>0.470721</td>\n",
       "      <td>0.337562</td>\n",
       "      <td>0.464974</td>\n",
       "      <td>0.512518</td>\n",
       "      <td>0.008231</td>\n",
       "      <td>7.762902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max_df=0.7, min_df=4</td>\n",
       "      <td>0.515593</td>\n",
       "      <td>0.518518</td>\n",
       "      <td>0.517051</td>\n",
       "      <td>0.438837</td>\n",
       "      <td>0.514411</td>\n",
       "      <td>0.584265</td>\n",
       "      <td>0.008722</td>\n",
       "      <td>8.570506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max_df=0.7, min_df=6</td>\n",
       "      <td>0.527135</td>\n",
       "      <td>0.527695</td>\n",
       "      <td>0.527415</td>\n",
       "      <td>0.457742</td>\n",
       "      <td>0.525981</td>\n",
       "      <td>0.597396</td>\n",
       "      <td>0.009779</td>\n",
       "      <td>9.381925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max_df=0.9, min_df=6</td>\n",
       "      <td>0.464370</td>\n",
       "      <td>0.474992</td>\n",
       "      <td>0.469621</td>\n",
       "      <td>0.351587</td>\n",
       "      <td>0.463063</td>\n",
       "      <td>0.524046</td>\n",
       "      <td>0.009552</td>\n",
       "      <td>9.456650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max_df=0.9, min_df=10</td>\n",
       "      <td>0.459944</td>\n",
       "      <td>0.474162</td>\n",
       "      <td>0.466945</td>\n",
       "      <td>0.346807</td>\n",
       "      <td>0.458625</td>\n",
       "      <td>0.522442</td>\n",
       "      <td>0.010918</td>\n",
       "      <td>10.913705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max_df=0.7, min_df=0.1</td>\n",
       "      <td>0.232931</td>\n",
       "      <td>0.237832</td>\n",
       "      <td>0.235356</td>\n",
       "      <td>0.213574</td>\n",
       "      <td>0.231058</td>\n",
       "      <td>0.420720</td>\n",
       "      <td>0.055309</td>\n",
       "      <td>53.015010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max_df=0.7, min_df=0.05</td>\n",
       "      <td>0.353540</td>\n",
       "      <td>0.373273</td>\n",
       "      <td>0.363138</td>\n",
       "      <td>0.271594</td>\n",
       "      <td>0.351961</td>\n",
       "      <td>0.471190</td>\n",
       "      <td>0.027054</td>\n",
       "      <td>24.169157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max_df=0.7, min_df=0.01</td>\n",
       "      <td>0.482718</td>\n",
       "      <td>0.545879</td>\n",
       "      <td>0.512359</td>\n",
       "      <td>0.433861</td>\n",
       "      <td>0.481453</td>\n",
       "      <td>0.601968</td>\n",
       "      <td>0.013793</td>\n",
       "      <td>13.565936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max_df=0.8, min_df=0.005</td>\n",
       "      <td>0.462009</td>\n",
       "      <td>0.474444</td>\n",
       "      <td>0.468144</td>\n",
       "      <td>0.348477</td>\n",
       "      <td>0.460696</td>\n",
       "      <td>0.522727</td>\n",
       "      <td>0.009918</td>\n",
       "      <td>9.898433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ExperimentName  homogeneity  completeness  v_measure  \\\n",
       "0       max_df=0.5, min_df=2     0.453964      0.463917   0.458886   \n",
       "1       max_df=0.5, min_df=4     0.513437      0.518966   0.516187   \n",
       "2       max_df=0.7, min_df=2     0.466276      0.475250   0.470721   \n",
       "3       max_df=0.7, min_df=4     0.515593      0.518518   0.517051   \n",
       "4       max_df=0.7, min_df=6     0.527135      0.527695   0.527415   \n",
       "5       max_df=0.9, min_df=6     0.464370      0.474992   0.469621   \n",
       "6      max_df=0.9, min_df=10     0.459944      0.474162   0.466945   \n",
       "7     max_df=0.7, min_df=0.1     0.232931      0.237832   0.235356   \n",
       "8    max_df=0.7, min_df=0.05     0.353540      0.373273   0.363138   \n",
       "9    max_df=0.7, min_df=0.01     0.482718      0.545879   0.512359   \n",
       "10  max_df=0.8, min_df=0.005     0.462009      0.474444   0.468144   \n",
       "\n",
       "    adj_rand_index  adjusted_mutual_info_score  fowlkes_mallows_score  \\\n",
       "0         0.320744                    0.452631               0.500960   \n",
       "1         0.447966                    0.512249               0.591984   \n",
       "2         0.337562                    0.464974               0.512518   \n",
       "3         0.438837                    0.514411               0.584265   \n",
       "4         0.457742                    0.525981               0.597396   \n",
       "5         0.351587                    0.463063               0.524046   \n",
       "6         0.346807                    0.458625               0.522442   \n",
       "7         0.213574                    0.231058               0.420720   \n",
       "8         0.271594                    0.351961               0.471190   \n",
       "9         0.433861                    0.481453               0.601968   \n",
       "10        0.348477                    0.460696               0.522727   \n",
       "\n",
       "    silhouette_coefficient  calinski_harabaz_score  \n",
       "0                 0.008181                7.822818  \n",
       "1                 0.008774                8.664423  \n",
       "2                 0.008231                7.762902  \n",
       "3                 0.008722                8.570506  \n",
       "4                 0.009779                9.381925  \n",
       "5                 0.009552                9.456650  \n",
       "6                 0.010918               10.913705  \n",
       "7                 0.055309               53.015010  \n",
       "8                 0.027054               24.169157  \n",
       "9                 0.013793               13.565936  \n",
       "10                0.009918                9.898433  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_constraints.compute_scores(['silhouette_coefficient', 'calinski_harabaz_score'])\n",
    "tfidf_constraints.result[['ExperimentName'] + SCORES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
