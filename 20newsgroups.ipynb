{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from newster import SingleExperiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from newster.clustering import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from newster.preprocessing import Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from newster.preprocessing.cleaner import ClearPunctuationRegex, LowerCase, ExcludeChars\n",
    "from newster.preprocessing.tokenizer import TextToWordsTokenizer\n",
    "from newster.preprocessing.utils import TokensToText\n",
    "from newster.preprocessing.vectorizer import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "categories = [\n",
    "    'alt.atheism',\n",
    "    'talk.religion.misc',\n",
    "    'comp.graphics',\n",
    "    'sci.space',\n",
    "]\n",
    "dataset = fetch_20newsgroups(\n",
    "    subset='test',\n",
    "    categories=categories,\n",
    "    shuffle=True,\n",
    "    random_state=42\n",
    ")\n",
    "labels = dataset.target\n",
    "true_k = np.unique(labels).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "exclude = set(punctuation + u'0123456789[]—«»–')\n",
    "\n",
    "preprocessing_steps = [\n",
    "    ExcludeChars(exclude=exclude),\n",
    "    LowerCase(),\n",
    "    # just to show how it works\n",
    "    TextToWordsTokenizer(),\n",
    "    TokensToText(),\n",
    "    TfidfVectorizer(stop_words='english')\n",
    "]\n",
    "preprocessor1 = Preprocessor(preprocessing_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from random import Random\n",
    "\n",
    "kmeans_euc = KMeans(true_k, distance='euclidean', rng=Random(42))\n",
    "\n",
    "kmeans_cosine = KMeans(true_k, distance='cosine', rng=Random(42))\n",
    "\n",
    "kmeans_pearson = KMeans(true_k, distance='correlation', rng=Random(42))\n",
    "kmeans_braycurtis = KMeans(true_k, distance='braycurtis', rng=Random(42))\n",
    "\n",
    "kmeans_chebyshev = KMeans(true_k, distance='chebyshev', rng=Random(42))\n",
    "kmeans_chebyshev.set_cluster_params(trace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_data_for_kmeans(matrix):\n",
    "    return matrix.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "experiment_euc = SingleExperiment(\n",
    "    data=dataset.data, \n",
    "    clustering_algorithm=kmeans_euc, \n",
    "    preprocessor=preprocessor1, \n",
    "    verbose_name='Euclid Kmeans on TfIdf',\n",
    "    prepare_func=prepare_data_for_kmeans\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment Euclid Kmeans on TfIdf\n",
      "Running preprocessing...\n",
      "Step#0: Exclude chars: 0.335907936096 sec\n",
      "Step#1: To lower case: 0.0128769874573 sec\n",
      "Step#2: From text to words tokenizer: 2.64668798447 sec\n",
      "Step#3: TokensToText: 0.0156409740448 sec\n",
      "Step#4: TfidfVectorizer: 0.557484149933 sec\n",
      "Running in-middle prepare function\n",
      "Running clustering...\n",
      "11.8588662148\n"
     ]
    }
   ],
   "source": [
    "experiment_euc.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To print summary set true_labels on experiment\n"
     ]
    }
   ],
   "source": [
    "experiment_euc.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_euc.clustering_algorithm.converged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_euc.clustering_algorithm.num_iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "experiment_euc.set_true_labels(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment Euclid Kmeans on TfIdf Summary\n",
      "-------------------\n",
      "Preprocessor:\n",
      "Step #0: Exclude chars\n",
      "Step #1: To lower case\n",
      "Step #2: From text to words tokenizer\n",
      "Step #3: TokensToText\n",
      "Step #4: TfidfVectorizer\n",
      "Clustering algorithm:\n",
      "K means\n",
      "Total objects to cluster: 1353\n",
      "Total clusters found: 4\n",
      "Cluster #0: 181 objects\n",
      "Cluster #1: 423 objects\n",
      "Cluster #2: 149 objects\n",
      "Cluster #3: 600 objects\n",
      ".......\n",
      "Scores:\n",
      "adj_rand_index: 0.341252415914\n",
      "completeness: 0.461619902217\n",
      "entropy: 1.23616079069\n",
      "v_measure: 0.437773343662\n",
      "homogeneity: 0.416269514837\n"
     ]
    }
   ],
   "source": [
    "experiment_euc.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0061880964996659203"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_euc.silhouette_coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "experiment_cosine = SingleExperiment(\n",
    "    data=dataset.data, \n",
    "    clustering_algorithm=kmeans_cosine, \n",
    "    preprocessor=preprocessor1, \n",
    "    verbose_name='Cosine Kmeans on TfIdf',\n",
    "    prepare_func=prepare_data_for_kmeans\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment Cosine Kmeans on TfIdf\n",
      "Running preprocessing...\n",
      "Step#0: Exclude chars: 0.330342054367 sec\n",
      "Step#1: To lower case: 0.0121281147003 sec\n",
      "Step#2: From text to words tokenizer: 2.09871387482 sec\n",
      "Step#3: TokensToText: 0.0139529705048 sec\n",
      "Step#4: TfidfVectorizer: 0.539141893387 sec\n",
      "Running in-middle prepare function\n",
      "Running clustering...\n",
      "7.74876999855\n"
     ]
    }
   ],
   "source": [
    "experiment_cosine.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "experiment_cosine.set_true_labels(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print experiment_cosine.clustering_algorithm.converged\n",
    "print experiment_cosine.clustering_algorithm.num_iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment Cosine Kmeans on TfIdf Summary\n",
      "-------------------\n",
      "Preprocessor:\n",
      "Step #0: Exclude chars\n",
      "Step #1: To lower case\n",
      "Step #2: From text to words tokenizer\n",
      "Step #3: TokensToText\n",
      "Step #4: TfidfVectorizer\n",
      "Clustering algorithm:\n",
      "K means\n",
      "Total objects to cluster: 1353\n",
      "Total clusters found: 4\n",
      "Cluster #0: 332 objects\n",
      "Cluster #1: 393 objects\n",
      "Cluster #2: 233 objects\n",
      "Cluster #3: 395 objects\n",
      ".......\n",
      "Scores:\n",
      "adj_rand_index: 0.422088057154\n",
      "completeness: 0.460662670533\n",
      "entropy: 1.36620392679\n",
      "v_measure: 0.459883388996\n",
      "homogeneity: 0.459106739555\n"
     ]
    }
   ],
   "source": [
    "experiment_cosine.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0062367881996818093"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_cosine.silhouette_coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "experiment_pearson = SingleExperiment(\n",
    "    data=dataset.data, \n",
    "    clustering_algorithm=kmeans_pearson, \n",
    "    preprocessor=preprocessor1, \n",
    "    verbose_name='Pearson Correlation Kmeans on TfIdf',\n",
    "    prepare_func=prepare_data_for_kmeans\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment Pearson Correlation Kmeans on TfIdf\n",
      "Running preprocessing...\n",
      "Step#0: Exclude chars: 0.363492965698 sec\n",
      "Step#1: To lower case: 0.0151379108429 sec\n",
      "Step#2: From text to words tokenizer: 2.26861786842 sec\n",
      "Step#3: TokensToText: 0.013571023941 sec\n",
      "Step#4: TfidfVectorizer: 0.555256128311 sec\n",
      "Running in-middle prepare function\n",
      "Running clustering...\n",
      "24.4648089409\n"
     ]
    }
   ],
   "source": [
    "experiment_pearson.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "experiment_pearson.set_true_labels(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "print experiment_pearson.clustering_algorithm.converged\n",
    "print experiment_pearson.clustering_algorithm.num_iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment Pearson Correlation Kmeans on TfIdf Summary\n",
      "-------------------\n",
      "Preprocessor:\n",
      "Step #0: Exclude chars\n",
      "Step #1: To lower case\n",
      "Step #2: From text to words tokenizer\n",
      "Step #3: TokensToText\n",
      "Step #4: TfidfVectorizer\n",
      "Clustering algorithm:\n",
      "K means\n",
      "Total objects to cluster: 1353\n",
      "Total clusters found: 4\n",
      "Cluster #0: 333 objects\n",
      "Cluster #1: 390 objects\n",
      "Cluster #2: 241 objects\n",
      "Cluster #3: 389 objects\n",
      ".......\n",
      "Scores:\n",
      "adj_rand_index: 0.427207915838\n",
      "completeness: 0.462395533902\n",
      "entropy: 1.3692983251\n",
      "v_measure: 0.462136381981\n",
      "homogeneity: 0.461877520383\n"
     ]
    }
   ],
   "source": [
    "experiment_pearson.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clustering': 24.46480894088745,\n",
       " 'preprocessor': {'Step#0: Exclude chars': 0.3634929656982422,\n",
       "  'Step#1: To lower case': 0.015137910842895508,\n",
       "  'Step#2: From text to words tokenizer': 2.268617868423462,\n",
       "  'Step#3: TokensToText': 0.013571023941040039,\n",
       "  'Step#4: TfidfVectorizer': 0.5552561283111572}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_pearson.spent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "experiment_braycurtis = SingleExperiment(\n",
    "    data=dataset.data, \n",
    "    clustering_algorithm=kmeans_braycurtis, \n",
    "    preprocessor=preprocessor1, \n",
    "    verbose_name='Bray-Curtis Kmeans on TfIdf',\n",
    "    prepare_func=prepare_data_for_kmeans\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment Bray-Curtis Kmeans on TfIdf\n",
      "Running preprocessing...\n",
      "Step#0: Exclude chars: 0.391551017761 sec\n",
      "Step#1: To lower case: 0.0128858089447 sec\n",
      "Step#2: From text to words tokenizer: 2.83308911324 sec\n",
      "Step#3: TokensToText: 0.0148909091949 sec\n",
      "Step#4: TfidfVectorizer: 0.69079208374 sec\n",
      "Running in-middle prepare function\n",
      "Running clustering...\n",
      "27.2871630192\n"
     ]
    }
   ],
   "source": [
    "experiment_braycurtis.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "experiment_braycurtis.set_true_labels(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "print experiment_braycurtis.clustering_algorithm.converged\n",
    "print experiment_braycurtis.clustering_algorithm.num_iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment Bray-Curtis Kmeans on TfIdf Summary\n",
      "-------------------\n",
      "Preprocessor:\n",
      "Step #0: Exclude chars\n",
      "Step #1: To lower case\n",
      "Step #2: From text to words tokenizer\n",
      "Step #3: TokensToText\n",
      "Step #4: TfidfVectorizer\n",
      "Clustering algorithm:\n",
      "K means\n",
      "Total objects to cluster: 1353\n",
      "Total clusters found: 4\n",
      "Cluster #0: 382 objects\n",
      "Cluster #1: 388 objects\n",
      "Cluster #2: 257 objects\n",
      "Cluster #3: 326 objects\n",
      ".......\n",
      "Scores:\n",
      "adj_rand_index: 0.436347148939\n",
      "completeness: 0.449388184194\n",
      "entropy: 1.37367028271\n",
      "v_measure: 0.449852592712\n",
      "homogeneity: 0.450317962085\n"
     ]
    }
   ],
   "source": [
    "experiment_braycurtis.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "experiment_chebyshev = SingleExperiment(\n",
    "    data=dataset.data, \n",
    "    clustering_algorithm=kmeans_chebyshev, \n",
    "    preprocessor=preprocessor1, \n",
    "    verbose_name='Pearson Correlation Kmeans on TfIdf',\n",
    "    prepare_func=prepare_data_for_kmeans\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment Pearson Correlation Kmeans on TfIdf\n",
      "Running preprocessing...\n",
      "Step#0: Exclude chars: 0.346951007843 sec\n",
      "Step#1: To lower case: 0.0140719413757 sec\n",
      "Step#2: From text to words tokenizer: 2.28541493416 sec\n",
      "Step#3: TokensToText: 0.0138800144196 sec\n",
      "Step#4: TfidfVectorizer: 0.539669036865 sec\n",
      "Running in-middle prepare function\n",
      "Running clustering...\n",
      "k-means trial 0\n",
      "iteration: 0\n",
      "difference: 0.92084566733\n",
      "iteration: 1\n",
      "difference: 0.226764006085\n",
      "iteration: 2\n",
      "difference: 0.345843826502\n",
      "iteration: 3\n",
      "difference: 0.349472390515\n",
      "iteration: 4\n",
      "difference: 0.142473889569\n",
      "iteration: 5\n",
      "difference: 0.03251004882\n",
      "iteration: 6\n",
      "difference: 0.0459499288652\n",
      "iteration: 7\n",
      "difference: 0.0093600085925\n",
      "iteration: 8\n",
      "difference: 0.0154949761166\n",
      "iteration: 9\n",
      "difference: 0.00812926443584\n",
      "iteration: 10\n",
      "difference: 0.00741747468431\n",
      "iteration: 11\n",
      "difference: 0.0044482379098\n",
      "iteration: 12\n",
      "difference: 0.0\n",
      "175.359150887\n"
     ]
    }
   ],
   "source": [
    "experiment_chebyshev.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "experiment_chebyshev.set_true_labels(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment Pearson Correlation Kmeans on TfIdf Summary\n",
      "-------------------\n",
      "Preprocessor:\n",
      "Step #0: Exclude chars\n",
      "Step #1: To lower case\n",
      "Step #2: From text to words tokenizer\n",
      "Step #3: TokensToText\n",
      "Step #4: TfidfVectorizer\n",
      "Clustering algorithm:\n",
      "K means\n",
      "Total objects to cluster: 1353\n",
      "Total clusters found: 4\n",
      "Cluster #0: 526 objects\n",
      "Cluster #1: 384 objects\n",
      "Cluster #2: 234 objects\n",
      "Cluster #3: 209 objects\n",
      ".......\n",
      "Scores:\n",
      "adj_rand_index: 0.0437650270214\n",
      "completeness: 0.0412266770296\n",
      "entropy: 1.31674025068\n",
      "v_measure: 0.0403968925512\n",
      "homogeneity: 0.0395998517823\n"
     ]
    }
   ],
   "source": [
    "experiment_chebyshev.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus MultiExperiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from newster import MultiExperimentiExperimenttiExperiment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
